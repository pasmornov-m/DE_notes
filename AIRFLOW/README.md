# AIRFLOW

---
## Введение

**AirFlow** — это платформа для программирования, планирования и мониторинга рабочих процессов.

Другими словами, AirFlow это **оркестратор** (не ELT-инструмент), в котором есть возможность прописывать ETL процессы, на языке Python. Каждый такой процесс представляет собой DAG, состоящий из определённых задач.

---

## DAG

DAG (Directed Acyclic Graph, направленный ациклический граф) представлет из себя набор задач (tasks), идущих последовательно друг за другом, либо параллельно, которые нельзя зациклить по кругу, т.е. своего рода строится прямолинейный конвеер обработки данных. Он может разветвляться, но никогда последующая задача не может обратиться к предыдущей.

![dag](../png/airflow_1.png)

*Пример DAG*

---

## Архитектура AirFlow

AirFlow состоит из четырёх основных, взаимосвязанных компонентов:

* Планировщик AirFlow (Scheduler)
* Исполнитель (Executor)
* Воркеры (Workers)
* Веб-сервер AirFlow

![Архитектура](../png/airflow_2.png)

---

### Планировщик (Scheduler)

- Планирование очереди графов.
- Проверка параметра **scheduler_interval**, который определяет частоту выполнения DAG;
- Мониторинг статуса — отслеживает успешность или неудачу выполнения каждой задачи;
- Catchup — Airflow по умолчанию запускает "наверстывающие" задания, если DAG не запускался в прошлые интервалы (например, если был остановлен).

---

### Исполнитель (Executor)

Executor (исполнитель) — это компонент, отвечающий за непосредственный запуск экземпляров задач, подготовленных планировщиком. Он определяет, как и где будут выполняться задачи DAG: локально, распределённо, параллельно или в контейнеризованных средах. Именно executor взаимодействует с рабочими процессами (worker’ами), управляет ресурсами и очередями, передаёт инструкции на выполнение задачи.

#### Виды исполнителей (executors) Airflow

- **SequentialExecutor** — по умолчанию, выполняет задачи строго по одной за раз. Используется для тестирования, дебага и простых сценариев.
- **LocalExecutor** — поддерживает параллельное выполнение задач на одном узле, порождая несколько процессов. Подходит для рабочих процессов на одной машине с ограниченной нагрузкой.
- **CeleryExecutor** — организует выполнение задач через распределённую очередь Celery, используя worker’ы на многих узлах. Требует настройки брокера сообщений (RabbitMQ, Redis). Повышает масштабируемость и отказоустойчивость, автоматически перераспределяя задачи в случае сбоя worker’а.
- **KubernetesExecutor** — запускает каждую задачу в отдельном контейнере Kubernetes. Идеально для сценариев с требованиями к изоляции, масштабируемости и распределению по кластерам Kubernetes.
- **DaskExecutor** — применяет кластер Dask для параллельных вычислений, удобен для задач машинного обучения и аналитики с большими объёмами данных.

#### Как работает executor

1. Планировщик определяет задачи для запуска и передаёт их executor’у.
2. Executor ставит задачу в очередь, распределяет ресурсы (если требуется).
3. Worker (или контейнер, в зависимости от типа executor’а) получает задачу, запускает действие, отслеживает статус (успех, ошибка, повторная попытка или перенос).
4. После завершения задачи результат записывается в базу метаданных Airflow и отображается в web-интерфейсе.

---

### Воркеры (Workers)

В Apache Airflow **workers** (рабочие процессы) — это компоненты, непосредственно выполняющие задачи, назначенные исполнителем (executor) по расписанию. Их роль, архитектура и способ запуска зависят от выбранного типа executor.

#### Основные функции workers

- **Выполнение задач DAG** — получая задачи от executor, worker запускает конкретные действия: обработку, загрузку, преобразование данных, отправку писем, вызов API и пр.
- **Изоляция и параллелизм** — workers позволяют запускать задачи параллельно и независимо друг от друга, увеличивая производительность системы.
- **Обработка ошибок и повторные попытки** — worker отслеживает статус выполнения, фиксирует ошибки, делает повторные попытки и возвращает статус задачи в базу метаданных Airflow.

#### Взаимодействие с executors

- В случае SequentialExecutor и LocalExecutor workers — это процессы внутри одного узла: задачи исполняются в отдельных потоках или процессах.
- Для CeleryExecutor каждый worker — это отдельный процесс (или контейнер/узел), слушающий очередь задач от брокера сообщений Celery (RabbitMQ/Redis). Задачи могут быть распределены по разным машинам, обеспечивая горизонтальное масштабирование и отказоустойчивость.
- В KubernetesExecutor worker'ы запускаются как отдельные ephemeral pods в Kubernetes: каждый pod выполняет только одну задачу и автоматически удаляется после завершения.
- Для других исполнителей (например, DaskExecutor) worker'ы — процессы Dask-кластера, оптимизированные для параллельной обработки аналитических и ML-задач.

---

### Веб-сервер AirFlow

- Визуализация DAG'а, который проанализировал планировщик;
- Предоставляет интерфейс пользователю для отслеживания работы DAG.

---

## Инициализация DAG и его основные параметры

В Python-файле DAG инициализируется очень просто, необходимо импортировать класс DAG из библиотеки AirFlow:

```
from airflow import DAG
```

И далее создать экземпляр объекта. Обычно переменную экземпляра принято называть **dag**.

```
dag = DAG(
    перечисление свойств
)
```

Именно этот экземпляр класса передаётся в дальнейшем каждому оператору, так оператор понимает, что принадлежит именно этому экземпляру.

```
PythonOperator(
  ...
  dag=dag
)
```

### Свойства экземпляра DAG

У экземпляра DAG есть большое количество свойств, но остановимся только на 3х, постоянно встречающихся в каждом DAG-экземпляре

1. **dag_id** — идентификатор DAG. Именно этот идентификатор проставляется в имени DAG на главной странице Airflow.

```
dag = DAG(
    dag_id = "load_file_to_psql"
    ...
)
```

2. **start_date** — задается дата и время начала планирования запусков DAG. Обычно для задания даты используется библиотека **datetime**.

```
import datetime as dt

dag = DAG(
    dag_id = "load_file_to_psql"
    start_date = dt.datetime(2024, 11, 13)
    ...
)
```

3. **schedule_interval** — планируемое время запуска DAG. 

```
import datetime as dt

dag = DAG(
    dag_id = "load_file_to_psql"
    start_date = dt.datetime(2024, 11, 13)
    schedule_interval = dt.timedelta(days=5) # раз в 5 дней, т.е. 13, 18, 23 и т.д.
    ...
)
```

В **schedule_interval** есть несколько способов задать время запуска. Ради примера в скобках будет указан ежедневный интервал.

* **CRON** — о нём во всех подробностях описано [здесь](../Linux/README.md). (schedule_interval = '0 0 * * *')
* **timedelta** — из библиотеки **datetime** (schedule_interval = dt.timedelta(days=5))
* макросы (schedule_interval = '@daily')
  
|**Макрос**|**Значение**|
|---|---|
|@once| Один и только один раз |
|@hourly| Запуск один раз в час в начале часа |
|@daily| Запуск один раз в день в полночь |
|@weekly| Запуск один раз в неделю в полночь в воскресенье утром|
|@monthly| Запуск один раз в месяц в полночь первого числа месяца|
|@yearly| Запуск один раз в год в полночь 1 января|

Если мы хотим запускать DAG вручную, то необходимо прописать значение **None** (schedule_interval = None)

### Статус DAG

Итоговый статус DAG зависит от статусов входящих в него задач. В некоторых сценариях корректное выполнение бизнес-логики может сопровождаться ошибками во второстепенных задачах, из-за чего DAG получает статус *failed*.

Распространённый подход — добавление **финальной служебной задачи**, которая:

* всегда выполняется последней;
* агрегирует результаты выполнения «критичных» и «некритичных» задач;
* выставляет итоговый статус DAG в соответствии с логикой процесса, а не только техническими ошибками отдельных шагов.

---

## Операторы AirFlow

DAG состоит из определённых задач, которые определяются **операторами**. 

В AirFlow существует множество операторов, с их полным списком можно ознакомиться [здесь](https://airflow.apache.org/docs/apache-airflow-providers/operators-and-hooks-ref/index.html)

Вот примеры часто встречающихся операторов:

* PythonOperator
* BashOperator
* PostgresOperator

## Параметры оператора

### trigger_rule

Параметр задачи, определяющий **условие её запуска** в зависимости от результатов выполнения upstream-задач.

* **all_success** — значение по умолчанию; задача запускается, если **все предыдущие задачи завершились успешно**.
* **one_success** — задача запускается, если **хотя бы одна предыдущая задача выполнена успешно**.
* **one_failed** — задача запускается, если **хотя бы одна предыдущая задача завершилась с ошибкой**.

### callback

Функция, вызываемая при определённом исходе выполнения оператора.
Не влияет на структуру DAG и выполняется как обработчик события задачи. Обычно это Python-функция, доступная в области видимости DAG.

* **on_failure_callback** — вызывается при ошибке выполнения задачи.

---

## Передача данных между задачами.
 
Существует 2 метода передачи данных между тасками в AirFlow:

1. Механизм XCom;
2. Сохранение данных в хранилищах.

### Механизм XCom

XCom - позволяет обмениваться сообщениями между задачами. Предназначен исключительно для **небольших данных**. 

Согласно документации в зависимости от используемой базы данных метаинформации:

* SQLite - до 2х Гб.
* PostgreSQL - до 1 Гб.
* MySQL - до 64 Кб.

**!!!Запомните!!!**
XCom можно использовать для передачи небольших объемов данных, например, значение агрегации, количества строк в файле, даже можно небольшой файл передать, но в остальных случаях используйте внешние решения для хранения данных. Например, сохраняйте все в каталог **tmp** и потом забирайте данные оттуда.

Определяется Xcom 2-мя способами:

* с помощью команд **xcom_push** и **xcom_pull**
* с помощью **Taskflow API** (декоратор **@task**, вот хорошая [статья](https://bigdataschool.ru/blog/taskflow-api-in-apache-airflow.html) с примером)

---

## Важные моменты

* Не размещайте исполняемый код и подключения к внешним системам в теле самого скрипта DAG.
Airflow постоянно сканирует папку с дагами, чтобы найти изменения. Если вы напишете запрос к базе данных или вызов API просто в коде (вне задач/тасок), этот запрос будет отправляться каждые несколько секунд. Это может «положить» базу данных и затормозить сам Airflow. Весь такой код должен находиться внутри операторов или вызываемых функций.

---

### Использованные ресурсы

[AIRFLOW (взято за основу)](https://halltape.github.io/HalltapeRoadmapDE/AIRFLOW/)