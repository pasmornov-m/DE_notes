# QUESTIONS

---

## **1. Хранилища данных (DWH, Data Lake, архитектура)**

* [Какие подходы построения хранилища данных тебе известны?](#подходы-построения-хранилища-данных)
* [Чем Data Lake отличается от DWH?](#чем-data-lake-отличается-от-dwh)
* [В чем разница подходов Кимболла и Инмона?](#разница-между-подходами-кимболла-и-инмона)
* Расскажи, что знаешь про SCD?
* Как сформировать процесс SCD2 для вставки, изменения, удаления?
* Расскажи какие слои есть в хранилище данных?
* Чем в хранилище ODS слой отличается от DDS слоя?

---

## **2. HDFS, Hadoop, Spark, Hive, Oozie, YARN**

* Что такое HDFS? Из чего она состоит и как работает?
* Какие проблемы бывают с HDFS?
* Что такое перекос данных?
* Как работает HSFD? Для чего нужна NameNode, Secondary NameNode? Нам необходимо считать текстовый файл из HDFS, объясни, что будет происходить?
* Что такое фактор репликации в HDFS и для чего он нужен?
* Что такое Hadoop и из каких компонентов он состоит?
* Что такое YARN?
* Для чего нужен Apache Oozie?
* Что такое Hive и объясни, как он работает с данными?
* Для чего нужен Hive?
* Что такое партиционирование и что оно из себя представляет в Hadoop?
* Что такое Spark? Для чего она нужна?
* Что делает Shuffle в Spark? Между чем передаются данные?
* Объясни парадигму MapReduce и почему Spark пришел ей на замену?
* Как передать UDF?

---

## **3. ClickHouse**

* Какие движки ClickHouse вы знаете?
* Какие особенности у движка ReplicatingMergeTree?
* Представь у тебя есть PGSQL и ClickHouse, как бы ты загружал данные из PGSQL в ClickHouse?
* Тебе необходимо из источника отправлять данные в нейронку каждые 10 минут, после чего результат записывать в ClickHouse, как ты это сделаешь? Опиши весь процесс.
* Как создать распределенную таблицу в Clickhouse?
* Какие движки в ClickHouse ты знаешь? И в чем их различия?
* Как оптимизировать запросы в Clickhouse?
* Как в Clickhouse устроена операция UPDATE?

---

## **4. Greenplum**

* В чем различие между GreenPlum и HDFS?
* Как происходит оптимизация запросов в GreenPlum?
* Для каких целей преднозначен Clickhouse и GreenPlum?

---

## **5. SQL, оконные функции, индексы, joins, СТЕ и др.**

* Что такое оконные функции?
* Как задать границы окна?
* В чем будет разница вывода, если я напишу агрегирующую оконную функцию по сумме с сортировкой и без неё?
* Представим что DENSE_RANK не существует, как сделать её функционал с помощью ROW_NUMBER?
* Чем отличается DENSE_RANK от RANK?
* Как правильно работать с таблицами, если 1я — это просто справочник (например, пользователи) построенный по SCD2, а 2я — это покупки пользователей, и необходимо найти все покупки пользователя с актуальными данными на день покупки.
* Какие виды exchange (motion) в Spark?
* Какие физические виды Join знаете?
* Что делает утилита PGTune?
* Что такое нормализация?
* Какие типы индексов бывают?
* Чем отличается кластеризованный индекс от некластеризованного?
* Сколько у таблицы может быть кластеризованных индексов?
* Есть ли ограничения на создание партицированной таблицы?
* Можно ли строить индекс по JSON полям?
* Чем отличаются типы данных JSON и JSONb?
* Чем отличаются материализованное и нематериализованное представления?
* Можно ли читать данные из материализованного представления, когда выполняется команда REFRESH?
* Как удалить дубликаты из таблицы?
* Как эффективно удалить дубликаты строк в большой таблице?
* Какой объявить СТЕ? Можно ли в одной таблице применить несколько СТЕ?
* Что из себя представляет СТЕ?
* Как оптимизируется запрос?
* Что будет делать, если в плане запроса увидели Nested Loop?
* Расскажи всё, что знаешь об индексах?
* Чем колоночные БД отличаются от строковых?

---

## **6. PostgreSQL (PGSQL)**

* Как выдаются права доступа в PostgreSQL?
* Как устроена система транзакций в PSQL?
* Какие блокировки существуют?

---

## **7. Apache NiFi**

* Какие процессоры использовали в NiFi?
* Настраивали ли схемы, если да, то в каких модулях?
* Как считать данные из каталога?
* Зачем при считывании CSV файлов данные переводили в AVRO формат?
* В случае сбоя одного сервера с NiFi — как его перезапустить?
* Чем Атрибут отличается от Контекста?
* Теряет ли данные NiFi, если произошел сбой программы?
* Расскажи о логировании в NiFi?
* Какой модуль в NiFi используется для JOLT преобразований?
* NiFi работает в кластере и считываем данные из Kafka, один из серверов сгорает, и мы теряем данные. Как повторно обработать потерянные данные?

---

## **8. Apache Airflow**

* Таска в AirFlow упала с ошибкой, как сделать так, чтобы несмотря на ошибку, следующая таска запустилась?
* Как в AirFlow в зависимости от условия, продолжить обработку по нужной ветке ДАГа?

---

## **9. Python: функции, декораторы, ООП и др.**

* Лямбда функция (что это, зачем, где использовать)
* Назовите парадигмы ООП?
* В чем разница "==" и "is"?
* Self (что это, для чего нужен, как и где использовать)
* В чем разница между `func` и `func()`?
* Назовите изменяемые и неизменяемые объекты.
* Декораторы (что, зачем нужно, как влияет на структуру) + написать свой пример
* Можно ли на одну функцию нацепить несколько декораторов и как они будут считываться?
* Функция, которая используется в качестве аргумента, может использовать свои аргументы?
* Что такое декоратор Шредингера?
* Как записывается декоратор?
* Генератор (что, зачем нужно) + написать свой пример
* Как рассчитывается сложность алгоритма? на примере list, tuple
* Как передаются аргументы в функцию?
* Зачем прописывать тип входящих или выходящих данных в функцию?
* Что такое super() и зачем нужен?
* Что такое итерация?
* Расскажи порядок разрешения методов?
* Что представляет из себя тип данных Int в Python?
* Какая типизация используется в Python?
* Можно ли в функции Python в качестве аргумента использовать функцию? Если да, то как называется такая функция?

---

# ANSWERS

---

## Подходы построения хранилища данных

### 1. Top-down (по Инмону)

#### Суть:

* Подход предполагает **централизованную архитектуру**, при которой в первую очередь создаётся **Enterprise Data Warehouse (EDW)** — единое корпоративное хранилище данных.
* Это хранилище содержит **нормализованные** данные (обычно 3NF), структурированные по предметным областям.

#### Особенности:

* EDW служит **единственным источником правды (Single Source of Truth)**.
* Из EDW создаются **витрины данных (Data Marts)**, уже в денормализованной форме — под нужды конкретных бизнес-пользователей или аналитиков.
* Основной акцент — **качество, консистентность, историчность**.

#### Плюсы:

* Централизованное управление метаданными и качеством данных.
* Удобно масштабировать и сопровождать на уровне всей организации.

#### Минусы:

* Высокая **стоимость и длительность внедрения**.
* Сложность в адаптации к изменяющимся бизнес-требованиям.

---

### 2. Bottom-up (по Кимболлу)

#### Суть:

* Построение хранилища начинается **с витрин данных (Data Marts)**, создаваемых для отдельных бизнес-процессов.
* Позже эти витрины объединяются в **логическое DWH**.

#### Особенности:

* Используется **денормализованная схема**, чаще всего **звезда** (star schema) или **снежинка** (snowflake).
* Данные моделируются вокруг **факт-таблиц** и **измерений**.
* Популярен благодаря своей **простоте и быстрому Time-to-Market**.

#### Плюсы:

* Быстрое получение бизнес-результатов.
* Относительно просто обучить и подключить конечных пользователей.
* Хорошая производительность при аналитических запросах.

#### Минусы:

* При масштабировании и объединении множества витрин возможно **дублирование логики**, **расхождение метрик**.
* Нет единого централизованного источника правды.

---

### 3. Data Vault

#### Суть:

* **Гибридный подход**, сочетающий достоинства Инмона и Кимболла.
* Разделяет структуру на **Hub (ключи сущностей)**, **Link (связи между сущностями)** и **Satellite (атрибуты, историчность)**.

#### Особенности:

* Поддерживает **историчность**, **аудит**, **многоверсионность**.
* Хорошо подходит для **Agile и DevOps** сред.
* Логика бизнес-преобразования вынесена за пределы core-структуры — в **Data Marts**.

#### Плюсы:

* Легко масштабируется и адаптируется под изменения схем источников.
* Строго отделяет бизнес-логику от данных.
* Хорошо подходит для **Big Data и распределённых систем**.

#### Минусы:

* Более **сложная модель**, требует грамотной ETL-реализации.
* Сложность в прямой аналитике без промежуточной агрегации.

---

### 4. Data Lake

#### Суть:

* Хранилище **сырого или полуобработанного** контента в виде файлов, таблиц, изображений и пр.
* Как правило, работает на базе **объектного хранилища**: S3, HDFS, Azure Blob.

#### Особенности:

* Используется в основном для **Big Data** и **Data Science** задач.
* Структура данных может быть **semi-structured** или **unstructured** (JSON, Parquet, Avro и пр.).
* Отложенная обработка (ELT, а не ETL).

#### Плюсы:

* Дешёвое масштабируемое хранилище.
* Гибкость в использовании — можно применять машинное обучение, потоковую обработку и пр.
* Подходит для хранения **огромных объёмов** разнотипных данных.

#### Минусы:

* Отсутствие схемы ведёт к **хаосу и "data swamp"**, если не настроены правила и метаданные.
* Сложнее обеспечить консистентность и управление качеством данных.

---

### 5. Lakehouse

#### Суть:

* Современный гибрид **Data Lake + Data Warehouse**.
* Использует движки вроде **Delta Lake**, **Apache Iceberg**, **Apache Hudi**, которые дают поддержку **ACID**, **time-travel**, **схем**, **индексов** и пр. поверх Data Lake.

#### Особенности:

* Хранение осуществляется в файловой системе, но с возможностями реляционной обработки.
* Работает с теми же инструментами, что и Data Lake (Spark, Presto, Dremio и др.).

#### Плюсы:

* Объединяет гибкость Data Lake с управляемостью DWH.
* Позволяет строить BI-отчёты и Data Science на одних и тех же данных.
* Хорошая производительность и контроль данных.

#### Минусы:

* Пока что менее зрелая технология, требует интеграции нескольких компонентов.
* Не всегда просто настраивается без облачных платформ (Databricks, Snowflake).

---

### 6. Lambda и Kappa архитектуры

#### Lambda Architecture:

* Объединяет **batch processing** (например, Hadoop/Spark) и **stream processing** (Kafka/Storm/Flink).
* Данные сначала обрабатываются в реальном времени (speed layer), а потом — партиями для точности (batch layer).
* Используется при требовании **быстрых и точных данных одновременно**.

#### Kappa Architecture:

* Упрощённая архитектура, в которой **все данные обрабатываются как поток**.
* Нет разделения на batch и stream — единый pipeline.

#### Плюсы:

* Lambda: высокая точность и скорость.
* Kappa: простота архитектуры, лучше подходит для событийных систем.

#### Минусы:

* Lambda: высокая сложность поддержки двух параллельных путей обработки.
* Kappa: сложнее корректировать ошибки в исторических данных.

---

**Заключение**:

Инмон и Кимболл — классические для BI, Data Vault — для гибкости и историчности, Data Lake и Lakehouse — для современных Big Data и ML-задач.

---

## Чем Data Lake отличается от DWH?

### 1. **Тип хранимых данных**

* **DWH (Data Warehouse):**

  * Хранит **структурированные данные** из различных источников, которые предварительно очищаются и трансформируются.
  * Используются реляционные базы данных, таблицы с жёстко заданными схемами.

* **Data Lake:**

  * Может хранить **любой тип данных**: структурированные (таблицы), полуструктурированные (JSON, XML), неструктурированные (изображения, видео, логи).
  * Данные загружаются "как есть", без строгой предварительной обработки (raw format).

---

### 2. **Схема и структура хранения**

* **DWH:**

  * Использует подход **schema-on-write** — данные приводятся к чёткой структуре **до** записи в хранилище.
  * Модель хранения разрабатывается заранее (звезда, снежинка, 3NF).

* **Data Lake:**

  * Использует подход **schema-on-read** — данные приводятся к нужной структуре **только во время чтения**.
  * Возможна работа с данными без заранее заданной схемы.

---

### 3. **Назначение**

* **DWH:**

  * Предназначено для **аналитики и бизнес-отчётности**.
  * Чётко определённые источники данных, высокая точность и надёжность.

* **Data Lake:**

  * Используется для **анализа больших объёмов разнородных данных**, в том числе для **Data Science**, **машинного обучения**, **потоковой обработки**.
  * Часто служит как единое хранилище "сырых" данных.

---

### 4. **Процесс загрузки данных**

* **DWH:**

  * Применяется классическая **ETL (Extract → Transform → Load)** схема: сначала данные очищаются и трансформируются, потом загружаются в хранилище.
* **Data Lake:**

  * Применяется **ELT (Extract → Load → Transform)**: данные сначала загружаются в lake, а потом обрабатываются по мере необходимости.

---

### 5. **Хранилище и технологии**

* **DWH:**

  * Обычно реализовано на **реляционных базах данных** (PostgreSQL, Oracle, Greenplum, Snowflake, MS SQL).
  * Поддерживает SQL-запросы и индексацию.

* **Data Lake:**

  * Строится на **объектных хранилищах** (Amazon S3, HDFS, Azure Blob).
  * Поддерживает работу с файлами (Parquet, ORC, Avro) и распределённую обработку (Spark, Presto, Flink).

---

### 6. **Гибкость и масштабируемость**

* **DWH:**

  * Ограничен типом данных и объёмами. Масштабируемость требует вертикального роста (более мощное железо).
  * Высокие требования к качеству и консистентности.

* **Data Lake:**

  * Гибок, масштабируется горизонтально. Подходит для хранения **петабайтов данных**.
  * Часто используется в **облачных инфраструктурах**.

---

### 7. **Стоимость**

* **DWH:**

  * Дороже в разработке и сопровождении, так как требует проектирования схем, ETL-процессов, инфраструктуры.

* **Data Lake:**

  * Относительно дешевле, особенно при использовании облачных решений. Не требует сложной подготовки данных перед загрузкой.


Оба подхода могут использоваться **совместно**, например: данные сначала собираются в Data Lake, затем после очистки и агрегации загружаются в DWH для бизнес-анализа. Такой гибридный подход особенно популярен в больших компаниях.

---

## Разница между подходами Кимболла и Инмона

Заключается в архитектуре построения хранилищ данных, способе организации данных, приоритетах и применении нормализации. Ниже подробно раскрыты основные различия между двумя подходами.

---

### 1. **Общий подход к построению хранилища**

**Инмон**:

* Считается «отцом корпоративного хранилища данных (EDW)».
* Подход **top-down** — сначала проектируется **централизованное хранилище**, потом на его основе строятся витрины данных для отдельных бизнес-подразделений.
* Основное внимание уделяется **централизованности и согласованности** данных.

**Кимболл**:

* Подход **bottom-up** — сначала создаются **витрины данных (Data Marts)** под конкретные бизнес-задачи, которые затем объединяются в единое логическое хранилище.
* Основной приоритет — **быстрое удовлетворение потребностей бизнеса**, простота реализации.

---

### 2. **Моделирование данных**

**Инмон**:

* Используется **нормализованная структура**, чаще всего **третья нормальная форма (3NF)**.
* Данные хранятся в виде **предметно-ориентированных таблиц**, связанных друг с другом через ключи.
* Цель — устранение избыточности, повышение целостности данных.

**Кимболл**:

* Используются **денормализованные структуры**, в частности **звёздная схема (star schema)** или **снежинка (snowflake schema)**.
* Основные сущности: **факт-таблицы** (события, числовые показатели) и **измерения** (атрибуты сущностей).
* Цель — обеспечить удобство и производительность аналитических запросов.

---

### 3. **Порядок загрузки и обработки данных**

**Инмон**:

* Используется классическая схема **ETL (Extract – Transform – Load)**.
* Данные сначала приводятся к строгой структуре, очищаются, нормализуются, а затем загружаются в хранилище.
* Требует тщательной подготовки и согласования схем.

**Кимболл**:

* Может использовать **ETL** или **ELT**, но основная задача — быстро и удобно представить данные бизнес-пользователям.
* Трансформации выполняются так, чтобы обеспечить удобство построения отчётов и анализа.

---

### 4. **Инфраструктура и масштабируемость**

**Инмон**:

* Предполагает создание **единого корпоративного хранилища**, которое служит универсальным источником данных для всех подразделений.
* Хорошо подходит для **больших организаций** с высокими требованиями к качеству данных и контролю.

**Кимболл**:

* Строится из **наборов независимых витрин**, каждая из которых разрабатывается быстро под конкретную задачу.
* Легче начать внедрение в условиях ограниченных ресурсов или при необходимости быстрого результата.

---

### 5. **Гибкость и сопровождение**

**Инмон**:

* **Менее гибкий**: изменение структуры требует серьёзных доработок в централизованной модели.
* Зато обеспечивает **долгосрочную устойчивость**, согласованность и прозрачность структуры данных.

**Кимболл**:

* **Более гибкий**: легко создавать и модифицировать витрины, адаптируя под новые задачи.
* При масштабировании и объединении витрин может возникнуть **дублирование данных и логики**.

---

### 6. **Пользователи и цели**

**Инмон**:

* Ориентирован на **ИТ-отделы и архитекторов**, строится с учётом стратегических целей и корпоративных требований.
* Часто используется в системах, где важна **аудитность, безопасность, соответствие нормативам**.

**Кимболл**:

* Ориентирован на **бизнес-пользователей и аналитиков**, которым нужны простые отчёты и быстрая аналитика.
* Хорошо подходит для **BI-инструментов** и визуализации данных.

---

### 7. **Примеры применения**

* **Инмон** — крупные организации, банки, телеком, госсектор, где важна высокая целостность и долгосрочная архитектура.
* **Кимболл** — небольшие и средние компании, или команды, которым нужно быстрое внедрение BI.

---

### Заключение

Подход Инмона подходит для создания масштабируемой, надёжной архитектуры, с акцентом на качество и контроль данных. Подход Кимболла — для быстрого внедрения аналитики и адаптивности к изменяющимся требованиям бизнеса.

На практике часто применяются **гибридные подходы**, где корпоративное хранилище проектируется по Инмону, а витрины — по Кимболлу. Это позволяет сочетать централизованность с удобством анализа.
