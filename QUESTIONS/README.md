# QUESTIONS

---

## **1. Хранилища данных (DWH, Data Lake, архитектура)**

* [Какие подходы построения хранилища данных тебе известны?](#подходы-построения-хранилища-данных)
* [Чем Data Lake отличается от DWH?](#чем-data-lake-отличается-от-dwh)
* [В чем разница подходов Кимболла и Инмона?](#разница-между-подходами-кимболла-и-инмона)
* [Расскажи, что знаешь про SCD?](#scd-slowly-changing-dimensions)
* [Как сформировать процесс SCD2 для вставки, изменения, удаления?](#как-реализовать-scd-type-2-на-примере-клиентов)
* [Как правильно работать с таблицами, если 1я — это просто справочник (например, пользователи) построенный по SCD2, а 2я — это покупки пользователей, и необходимо найти все покупки пользователя с актуальными данными на день покупки.](#как-правильно-работать-с-таблицами-если-1я--это-просто-справочник-например-пользователи-построенный-по-scd2-а-2я--это-покупки-пользователей-и-необходимо-найти-все-покупки-пользователя-с-актуальными-данными-на-день-покупки)
* [Расскажи какие слои есть в хранилище данных?](#слои-в-хранилище-данных)
* [Чем в хранилище ODS слой отличается от DDS слоя?](#слои-в-хранилище-данных)

---

## **2. HDFS, Hadoop, Spark, Hive, Oozie, YARN**

* Что такое HDFS? Из чего она состоит и как работает?
* Какие проблемы бывают с HDFS?
* Что такое перекос данных?
* Как работает HSFD? Для чего нужна NameNode, Secondary NameNode? Нам необходимо считать текстовый файл из HDFS, объясни, что будет происходить?
* Что такое фактор репликации в HDFS и для чего он нужен?
* Что такое Hadoop и из каких компонентов он состоит?
* Что такое YARN?
* Для чего нужен Apache Oozie?
* Что такое Hive и объясни, как он работает с данными?
* Что такое партиционирование и что оно из себя представляет в Hadoop?
* Что такое Spark? Для чего она нужна?
* Что делает Shuffle в Spark? Между чем передаются данные?
* Объясни парадигму MapReduce и почему Spark пришел ей на замену?
* Какие виды exchange (motion) в Spark?
* Как передать UDF?
* Расскажите про Job stage task в Spark.
* Что такое catalyst?

---

## **3. ClickHouse**

* Какие движки ClickHouse вы знаете?
* Какие особенности у движка ReplicatingMergeTree?
* Представь у тебя есть PGSQL и ClickHouse, как бы ты загружал данные из PGSQL в ClickHouse?
* Тебе необходимо из источника отправлять данные в нейронку каждые 10 минут, после чего результат записывать в ClickHouse, как ты это сделаешь? Опиши весь процесс.
* Как создать распределенную таблицу в Clickhouse?
* Какие движки в ClickHouse ты знаешь? И в чем их различия?
* Как оптимизировать запросы в Clickhouse?
* Как в Clickhouse устроена операция UPDATE?

---

## **4. Greenplum**

* В чем различие между GreenPlum и HDFS?
* Как происходит оптимизация запросов в GreenPlum?
* Для каких целей преднозначен Clickhouse и GreenPlum?

---

## **5. SQL, оконные функции, индексы, joins, СТЕ и др.**

* Что такое оконные функции?
* Как задать границы окна?
* В чем будет разница вывода, если я напишу агрегирующую оконную функцию по сумме с сортировкой и без неё?
* Чем отличаются оконные функции от агрегирующих в SQL?
* Можно ли использовать несколько агрегационных функций в select?
* Представим что DENSE_RANK не существует, как сделать её функционал с помощью ROW_NUMBER?
* Чем отличается DENSE_RANK от RANK?
* Как RANK() работает с NULL?
* У вас есть поле с datetime,  а вам надо сделать фильтр по дате без учета времени - перечислите возможные способы решения проблемы.
* Перечислите логические и физические джойны и алгоритмическую сложность физических.
* Что делает утилита PGTune?
* Что такое нормализация?
* Какие типы индексов бывают?
* Чем отличается кластеризованный индекс от некластеризованного?
* Сколько у таблицы может быть кластеризованных индексов?
* Есть ли ограничения на создание партицированной таблицы?
* Можно ли строить индекс по JSON полям?
* Чем отличаются типы данных JSON и JSONb?
* Чем отличаются материализованное и нематериализованное представления?
* Можно ли читать данные из материализованного представления, когда выполняется команда REFRESH?
* Как удалить дубликаты из таблицы?
* Как эффективно удалить дубликаты строк в большой таблице?
* Какой объявить СТЕ? Можно ли в одной таблице применить несколько СТЕ?
* Что из себя представляет СТЕ?
* Как оптимизируется запрос?
* Что будет делать, если в плане запроса увидели Nested Loop?
* Чем колоночные БД отличаются от строковых?

---

## **6. PostgreSQL (PGSQL)**

* Как выдаются права доступа в PostgreSQL?
* Как устроена система транзакций в PSQL?
* Какие блокировки существуют?

---

## **7. Apache NiFi**

* Какие процессоры использовали в NiFi?
* Настраивали ли схемы, если да, то в каких модулях?
* Как считать данные из каталога?
* Зачем при считывании CSV файлов данные переводили в AVRO формат?
* В случае сбоя одного сервера с NiFi — как его перезапустить?
* Чем Атрибут отличается от Контекста?
* Теряет ли данные NiFi, если произошел сбой программы?
* Расскажи о логировании в NiFi?
* Какой модуль в NiFi используется для JOLT преобразований?
* NiFi работает в кластере и считываем данные из Kafka, один из серверов сгорает, и мы теряем данные. Как повторно обработать потерянные данные?

---

## **8. Apache Airflow**

* Таска в AirFlow упала с ошибкой, как сделать так, чтобы несмотря на ошибку, следующая таска запустилась?
* Как в AirFlow в зависимости от условия, продолжить обработку по нужной ветке ДАГа?
* Что такое Dataset в Airflow?
* Что представляет из себя Sensor в Airflow?
* Как передавать данные между задачами в Airflow? (ответа xcom не достаточно)

---

## **9. Python: функции, декораторы, ООП и др.**

* [Лямбда функция (что это, зачем, где использовать)](#лямбда-функция-что-это-зачем-где-использовать)
* [В чем разница "==" и "is"?](#в-чем-разница--и-is)
* [В чем разница между `func` и `func()`?](#в-чем-разница-между-func-и-func)
* [Назовите изменяемые и неизменяемые объекты (типы).](#назовите-изменяемые-и-неизменяемые-объекты-типы)
* [Декораторы (что, зачем нужно, как влияет на структуру) + написать свой пример](#декораторы-что-зачем-нужно-как-влияет-на-структуру--написать-свой-пример)
* Можно ли на одну функцию нацепить несколько декораторов и как они будут считываться?
* Функция, которая используется в качестве аргумента, может использовать свои аргументы?
* Что такое декоратор Шредингера?
* Генератор (что, зачем нужно) + написать свой пример
* Как рассчитывается сложность алгоритма? на примере list, tuple
* Как передаются аргументы в функцию?
* Зачем прописывать тип входящих или выходящих данных в функцию?
* Назовите парадигмы ООП?
* Self (что это, для чего нужен, как и где использовать)
* Что такое super() и зачем нужен?
* Что такое итерация?
* Расскажи порядок разрешения методов?
* Что представляет из себя тип данных Int в Python?
* Какая типизация используется в Python?
* Можно ли в функции Python в качестве аргумента использовать функцию? Если да, то как называется такая функция?
* Какие типы данных могут быть ключами словаря?
* Может ли изменяться порядок ключей в словаре?
* Какая алгоритмическая сложность у получения значения по ключу из словаря?
* Кортеж может быть ключом словаря?
* Какие магические методы должны быть реализованы в в классе, чтоб его можно было использовать в качестве ключа словаря? 
* Что такое контекстный менеджер?
* Как реализовать контекстный менеджер? Если ответите через класс, то попросят назвать и другие варианты.
* Какие методы необходимо реализовать в классе, чтобы он мог использоваться как контекстный менеджер?
* Что такое class methods / static methods?
* Что такое GIL?
* Чем модуль отличается от пакета?

---

# ANSWERS

---

**1. Хранилища данных (DWH, Data Lake, архитектура)**

---

## Подходы построения хранилища данных

### 1. Top-down (по Инмону)

#### Суть:

* Подход предполагает **централизованную архитектуру**, при которой в первую очередь создаётся **Enterprise Data Warehouse (EDW)** — единое корпоративное хранилище данных.
* Это хранилище содержит **нормализованные** данные (обычно 3NF), структурированные по предметным областям.

#### Особенности:

* EDW служит **единственным источником правды (Single Source of Truth)**.
* Из EDW создаются **витрины данных (Data Marts)**, уже в денормализованной форме — под нужды конкретных бизнес-пользователей или аналитиков.
* Основной акцент — **качество, консистентность, историчность**.

#### Плюсы:

* Централизованное управление метаданными и качеством данных.
* Удобно масштабировать и сопровождать на уровне всей организации.

#### Минусы:

* Высокая **стоимость и длительность внедрения**.
* Сложность в адаптации к изменяющимся бизнес-требованиям.

---

### 2. Bottom-up (по Кимболлу)

#### Суть:

* Построение хранилища начинается **с витрин данных (Data Marts)**, создаваемых для отдельных бизнес-процессов.
* Позже эти витрины объединяются в **логическое DWH**.

#### Особенности:

* Используется **денормализованная схема**, чаще всего **звезда** (star schema) или **снежинка** (snowflake).
* Данные моделируются вокруг **факт-таблиц** и **измерений**.
* Популярен благодаря своей **простоте и быстрому Time-to-Market**.

#### Плюсы:

* Быстрое получение бизнес-результатов.
* Относительно просто обучить и подключить конечных пользователей.
* Хорошая производительность при аналитических запросах.

#### Минусы:

* При масштабировании и объединении множества витрин возможно **дублирование логики**, **расхождение метрик**.
* Нет единого централизованного источника правды.

---

### 3. Data Vault

#### Суть:

* **Гибридный подход**, сочетающий достоинства Инмона и Кимболла.
* Разделяет структуру на **Hub (ключи сущностей)**, **Link (связи между сущностями)** и **Satellite (атрибуты, историчность)**.

#### Особенности:

* Поддерживает **историчность**, **аудит**, **многоверсионность**.
* Хорошо подходит для **Agile и DevOps** сред.
* Логика бизнес-преобразования вынесена за пределы core-структуры — в **Data Marts**.

#### Плюсы:

* Легко масштабируется и адаптируется под изменения схем источников.
* Строго отделяет бизнес-логику от данных.
* Хорошо подходит для **Big Data и распределённых систем**.

#### Минусы:

* Более **сложная модель**, требует грамотной ETL-реализации.
* Сложность в прямой аналитике без промежуточной агрегации.

---

### 4. Data Lake

#### Суть:

* Хранилище **сырого или полуобработанного** контента в виде файлов, таблиц, изображений и пр.
* Как правило, работает на базе **объектного хранилища**: S3, HDFS, Azure Blob.

#### Особенности:

* Используется в основном для **Big Data** и **Data Science** задач.
* Структура данных может быть **semi-structured** или **unstructured** (JSON, Parquet, Avro и пр.).
* Отложенная обработка (ELT, а не ETL).

#### Плюсы:

* Дешёвое масштабируемое хранилище.
* Гибкость в использовании — можно применять машинное обучение, потоковую обработку и пр.
* Подходит для хранения **огромных объёмов** разнотипных данных.

#### Минусы:

* Отсутствие схемы ведёт к **хаосу и "data swamp"**, если не настроены правила и метаданные.
* Сложнее обеспечить консистентность и управление качеством данных.

---

### 5. Lakehouse

#### Суть:

* Современный гибрид **Data Lake + Data Warehouse**.
* Использует движки вроде **Delta Lake**, **Apache Iceberg**, **Apache Hudi**, которые дают поддержку **ACID**, **time-travel**, **схем**, **индексов** и пр. поверх Data Lake.

#### Особенности:

* Хранение осуществляется в файловой системе, но с возможностями реляционной обработки.
* Работает с теми же инструментами, что и Data Lake (Spark, Presto, Dremio и др.).

#### Плюсы:

* Объединяет гибкость Data Lake с управляемостью DWH.
* Позволяет строить BI-отчёты и Data Science на одних и тех же данных.
* Хорошая производительность и контроль данных.

#### Минусы:

* Пока что менее зрелая технология, требует интеграции нескольких компонентов.
* Не всегда просто настраивается без облачных платформ (Databricks, Snowflake).

---

### 6. Lambda и Kappa архитектуры

#### Lambda Architecture:

* Объединяет **batch processing** (например, Hadoop/Spark) и **stream processing** (Kafka/Storm/Flink).
* Данные сначала обрабатываются в реальном времени (speed layer), а потом — партиями для точности (batch layer).
* Используется при требовании **быстрых и точных данных одновременно**.

#### Kappa Architecture:

* Упрощённая архитектура, в которой **все данные обрабатываются как поток**.
* Нет разделения на batch и stream — единый pipeline.

#### Плюсы:

* Lambda: высокая точность и скорость.
* Kappa: простота архитектуры, лучше подходит для событийных систем.

#### Минусы:

* Lambda: высокая сложность поддержки двух параллельных путей обработки.
* Kappa: сложнее корректировать ошибки в исторических данных.

---

**Заключение**:

Инмон и Кимболл — классические для BI, Data Vault — для гибкости и историчности, Data Lake и Lakehouse — для современных Big Data и ML-задач.

---

## Чем Data Lake отличается от DWH?

### 1. **Тип хранимых данных**

* **DWH (Data Warehouse):**

  * Хранит **структурированные данные** из различных источников, которые предварительно очищаются и трансформируются.
  * Используются реляционные базы данных, таблицы с жёстко заданными схемами.

* **Data Lake:**

  * Может хранить **любой тип данных**: структурированные (таблицы), полуструктурированные (JSON, XML), неструктурированные (изображения, видео, логи).
  * Данные загружаются "как есть", без строгой предварительной обработки (raw format).

---

### 2. **Схема и структура хранения**

* **DWH:**

  * Использует подход **schema-on-write** — данные приводятся к чёткой структуре **до** записи в хранилище.
  * Модель хранения разрабатывается заранее (звезда, снежинка, 3NF).

* **Data Lake:**

  * Использует подход **schema-on-read** — данные приводятся к нужной структуре **только во время чтения**.
  * Возможна работа с данными без заранее заданной схемы.

---

### 3. **Назначение**

* **DWH:**

  * Предназначено для **аналитики и бизнес-отчётности**.
  * Чётко определённые источники данных, высокая точность и надёжность.

* **Data Lake:**

  * Используется для **анализа больших объёмов разнородных данных**, в том числе для **Data Science**, **машинного обучения**, **потоковой обработки**.
  * Часто служит как единое хранилище "сырых" данных.

---

### 4. **Процесс загрузки данных**

* **DWH:**

  * Применяется классическая **ETL (Extract → Transform → Load)** схема: сначала данные очищаются и трансформируются, потом загружаются в хранилище.
* **Data Lake:**

  * Применяется **ELT (Extract → Load → Transform)**: данные сначала загружаются в lake, а потом обрабатываются по мере необходимости.

---

### 5. **Хранилище и технологии**

* **DWH:**

  * Обычно реализовано на **реляционных базах данных** (PostgreSQL, Oracle, Greenplum, Snowflake, MS SQL).
  * Поддерживает SQL-запросы и индексацию.

* **Data Lake:**

  * Строится на **объектных хранилищах** (Amazon S3, HDFS, Azure Blob).
  * Поддерживает работу с файлами (Parquet, ORC, Avro) и распределённую обработку (Spark, Presto, Flink).

---

### 6. **Гибкость и масштабируемость**

* **DWH:**

  * Ограничен типом данных и объёмами. Масштабируемость требует вертикального роста (более мощное железо).
  * Высокие требования к качеству и консистентности.

* **Data Lake:**

  * Гибок, масштабируется горизонтально. Подходит для хранения **петабайтов данных**.
  * Часто используется в **облачных инфраструктурах**.

---

### 7. **Стоимость**

* **DWH:**

  * Дороже в разработке и сопровождении, так как требует проектирования схем, ETL-процессов, инфраструктуры.

* **Data Lake:**

  * Относительно дешевле, особенно при использовании облачных решений. Не требует сложной подготовки данных перед загрузкой.


Оба подхода могут использоваться **совместно**, например: данные сначала собираются в Data Lake, затем после очистки и агрегации загружаются в DWH для бизнес-анализа. Такой гибридный подход особенно популярен в больших компаниях.

---

## Разница между подходами Кимболла и Инмона

Заключается в архитектуре построения хранилищ данных, способе организации данных, приоритетах и применении нормализации. Ниже подробно раскрыты основные различия между двумя подходами.

---

### 1. **Общий подход к построению хранилища**

**Инмон**:

* Считается «отцом корпоративного хранилища данных (EDW)».
* Подход **top-down** — сначала проектируется **централизованное хранилище**, потом на его основе строятся витрины данных для отдельных бизнес-подразделений.
* Основное внимание уделяется **централизованности и согласованности** данных.

**Кимболл**:

* Подход **bottom-up** — сначала создаются **витрины данных (Data Marts)** под конкретные бизнес-задачи, которые затем объединяются в единое логическое хранилище.
* Основной приоритет — **быстрое удовлетворение потребностей бизнеса**, простота реализации.

---

### 2. **Моделирование данных**

**Инмон**:

* Используется **нормализованная структура**, чаще всего **третья нормальная форма (3NF)**.
* Данные хранятся в виде **предметно-ориентированных таблиц**, связанных друг с другом через ключи.
* Цель — устранение избыточности, повышение целостности данных.

**Кимболл**:

* Используются **денормализованные структуры**, в частности **звёздная схема (star schema)** или **снежинка (snowflake schema)**.
* Основные сущности: **факт-таблицы** (события, числовые показатели) и **измерения** (атрибуты сущностей).
* Цель — обеспечить удобство и производительность аналитических запросов.

---

### 3. **Порядок загрузки и обработки данных**

**Инмон**:

* Используется классическая схема **ETL (Extract – Transform – Load)**.
* Данные сначала приводятся к строгой структуре, очищаются, нормализуются, а затем загружаются в хранилище.
* Требует тщательной подготовки и согласования схем.

**Кимболл**:

* Может использовать **ETL** или **ELT**, но основная задача — быстро и удобно представить данные бизнес-пользователям.
* Трансформации выполняются так, чтобы обеспечить удобство построения отчётов и анализа.

---

### 4. **Инфраструктура и масштабируемость**

**Инмон**:

* Предполагает создание **единого корпоративного хранилища**, которое служит универсальным источником данных для всех подразделений.
* Хорошо подходит для **больших организаций** с высокими требованиями к качеству данных и контролю.

**Кимболл**:

* Строится из **наборов независимых витрин**, каждая из которых разрабатывается быстро под конкретную задачу.
* Легче начать внедрение в условиях ограниченных ресурсов или при необходимости быстрого результата.

---

### 5. **Гибкость и сопровождение**

**Инмон**:

* **Менее гибкий**: изменение структуры требует серьёзных доработок в централизованной модели.
* Зато обеспечивает **долгосрочную устойчивость**, согласованность и прозрачность структуры данных.

**Кимболл**:

* **Более гибкий**: легко создавать и модифицировать витрины, адаптируя под новые задачи.
* При масштабировании и объединении витрин может возникнуть **дублирование данных и логики**.

---

### 6. **Пользователи и цели**

**Инмон**:

* Ориентирован на **ИТ-отделы и архитекторов**, строится с учётом стратегических целей и корпоративных требований.
* Часто используется в системах, где важна **аудитность, безопасность, соответствие нормативам**.

**Кимболл**:

* Ориентирован на **бизнес-пользователей и аналитиков**, которым нужны простые отчёты и быстрая аналитика.
* Хорошо подходит для **BI-инструментов** и визуализации данных.

---

### 7. **Примеры применения**

* **Инмон** — крупные организации, банки, телеком, госсектор, где важна высокая целостность и долгосрочная архитектура.
* **Кимболл** — небольшие и средние компании, или команды, которым нужно быстрое внедрение BI.

---

### Заключение

Подход Инмона подходит для создания масштабируемой, надёжной архитектуры, с акцентом на качество и контроль данных. Подход Кимболла — для быстрого внедрения аналитики и адаптивности к изменяющимся требованиям бизнеса.

На практике часто применяются **гибридные подходы**, где корпоративное хранилище проектируется по Инмону, а витрины — по Кимболлу. Это позволяет сочетать централизованность с удобством анализа.

---

## SCD (Slowly Changing Dimensions)

### Что такое SCD?

**SCD (медленно изменяющиеся измерения)** — это справочные таблицы (например, клиенты, продукты, сотрудники), данные в которых изменяются **редко**, но такие изменения необходимо **хранить** и учитывать в аналитике. Например, клиент сменил адрес или должность, и важно понимать, как его поведение или метрики менялись до и после этого события.

---

### Основные типы SCD

#### **SCD Type 0 — неизменяемые измерения**

* Данные в таблице **никогда не изменяются** после загрузки.
* Используется для атрибутов, которые не должны пересматриваться (например, дата рождения).
* Любое изменение источника игнорируется.

**Применение:** паспортные данные, пол, дата рождения.

---

#### **SCD Type 1 — перезапись (overwrite)**

* Изменения **перезаписываются**: старое значение теряется, хранится только актуальное.
* Простой в реализации, но не даёт возможности проанализировать прошлое значение.

**Пример:** клиент сменил город — в таблице просто обновляется значение поля `city`.

**Плюсы:** простая реализация, экономит место.
**Минусы:** невозможно восстановить историю изменений.

---

#### **SCD Type 2 — хранение полной истории изменений**

* Каждое изменение приводит к **созданию новой строки** в таблице.
* Используются специальные поля:

  * `valid_from` / `valid_to` (период действия записи),
  * `is_current` (флаг актуальности),
  * `version` (опционально).

**Пример:** при смене адреса у клиента будет две строки: одна с прошлым адресом, другая — с новым, и только одна из них будет помечена как текущая.

**Плюсы:** можно проводить анализ в ретроспективе, отслеживать, когда и какие изменения происходили.
**Минусы:** большее потребление памяти, усложнённая логика работы.

---

#### **SCD Type 3 — хранение части истории**

* Хранится только **одно предыдущее значение** вместе с текущим (например, `previous_city`, `current_city`).
* Подходит, когда не требуется глубокая история изменений.

**Пример:** для клиента можно хранить текущий и предыдущий адрес, но не более.

**Плюсы:** экономия места.
**Минусы:** ограниченная аналитическая ценность, невозможно отследить более двух состояний.

---

### Другие типы (используемые реже):

#### SCD Type 4 — журнал изменений (Change History Table)

* История хранится **в отдельной таблице**, а основная справочная содержит только актуальные данные.
* Используется для минимизации нагрузки на основную таблицу и для удобной работы с историей.

#### SCD Type 6 — гибрид 1+2+3

* Сочетает сразу несколько стратегий:

  * перезапись текущих значений (как Type 1),
  * хранение истории в виде новых строк (как Type 2),
  * сохранение предыдущего значения в колонке (как Type 3).
* Применяется в системах с высокими требованиями к аналитике.

---

### Зачем нужен SCD?

* Для корректного анализа данных во времени.
* Чтобы избежать искажений в отчётах при изменении справочной информации.
* Для соответствия требованиям аудита и нормативного учёта (например, в банковской или медицинской сфере).

---

### Технические аспекты:

* Важно использовать **бизнес-ключи**, а не surrogate-ключи (primary key), для определения изменений.
* Для Type 2 часто добавляют поля:

  * `surrogate_key` (уникальный ID строки),
  * `valid_from`, `valid_to`,
  * `version`,
  * `is_current`.


---

### Как реализовать SCD Type 2 (на примере клиентов):

Обработка включает три сценария: **вставка новой записи**, **изменение существующей записи** и **обработка удаления**.

#### 1. **Вставка новой записи (insert)**

Если в целевой таблице нет строки с таким `business_key` (например, `customer_id`):

* Вставить новую строку с:

  * `valid_from = now()`
  * `valid_to = NULL`
  * `is_current = true`
  * другими полями, соответствующими входным данным.

---

#### 2. **Изменение существующей записи (update)**

Если запись с `business_key` существует и флаг `is_current = true`, нужно проверить: изменились ли **отслеживаемые** атрибуты (например, адрес, должность и т.д.):

* **Если атрибуты изменились:**

  * Завершить старую запись:

    * `valid_to = now()`
    * `is_current = false`
  * Вставить новую строку:

    * `valid_from = now()`
    * `valid_to = NULL`
    * `is_current = true`
    * с обновлёнными значениями полей.

* **Если изменений нет:**

  * Ничего не делать (данные актуальны, история не нарушается).

---

#### 3. **Удаление записи (delete / логическое удаление)**

Удаления в SCD2 обычно не означают физическое удаление строки, а оформляются как **завершение действия записи**:

* Найти текущую активную запись (`is_current = true`);
* Обновить:

  * `valid_to = now()`
  * `is_current = false`
* (Опционально) добавить логическое поле `is_deleted = true` в новую запись, если требуется отражение удаления.

**Важно:** Если необходимо вести учёт «удалённых» записей (например, клиент ушёл), можно создать новую строку с тем же `business_key`, но с флагом `is_deleted = true`, чтобы сохранялась история.

---

### Как правильно работать с таблицами, если 1я — это просто справочник (например, пользователи) построенный по SCD2, а 2я — это покупки пользователей, и необходимо найти все покупки пользователя с актуальными данными на день покупки.

#### Условия задачи

* **Таблица `users_scd2`** — справочник пользователей, ведётся по SCD Type 2, содержит:

  * `user_id` — бизнес-ключ (natural key);
  * `valid_from` и `valid_to` — диапазон действия версии;
  * `is_current` — флаг актуальности;
  * другие атрибуты (например, `user_city`, `user_status` и т.д.).

* **Таблица `purchases`** — факт-покупки:

  * `user_id` — внешний ключ на пользователя;
  * `purchase_date` — дата покупки;
  * другие атрибуты (сумма, товар и т.д.).

---

#### Цель

Найти все покупки пользователей, при этом — к каждой покупке прикрепить актуальную на **дату покупки** версию пользователя из таблицы `users_scd2`.

---

#### Правильный подход

Для этого выполняется **темпоральное соединение (range join)** по следующему условию:

```sql
purchases.user_id = users_scd2.user_id
AND purchases.purchase_date >= users_scd2.valid_from
AND (purchases.purchase_date < users_scd2.valid_to OR users_scd2.valid_to IS NULL)
```

---

## Пример SQL-запроса

```sql
SELECT
    p.purchase_id,
    p.user_id,
    p.purchase_date,
    p.amount,
    u.user_city,
    u.user_status
FROM
    purchases p
JOIN
    users_scd2 u
    ON p.user_id = u.user_id
   AND p.purchase_date >= u.valid_from
   AND (p.purchase_date < u.valid_to OR u.valid_to IS NULL);
```

---

## Объяснение условий

* `p.user_id = u.user_id` — обычное соединение по бизнес-ключу;
* `p.purchase_date >= u.valid_from` — дата покупки должна быть позже начала действия версии;
* `p.purchase_date < u.valid_to OR u.valid_to IS NULL` — покупка произошла до конца действия версии, или же версия ещё актуальна (в этом случае `valid_to` = `NULL`).

Таким образом, к каждой покупке будет привязана именно **та версия пользователя**, которая была действующей в момент совершения этой покупки.

---

## Слои в хранилище данных

Хранилище данных (Data Warehouse, DWH) строится по **многоуровневой архитектуре**, где каждый слой выполняет свою специфическую задачу и служит промежуточным этапом обработки данных. Это позволяет обеспечить надёжность, масштабируемость и упрощает сопровождение системы.

---

### 1. **Staging Area (или Raw/Buffer Layer)**

**Назначение:** временное хранилище "сырых" данных, загружаемых из источников.
**Характеристики:**

* Данные поступают в том виде, в котором они есть в источниках (CRM, ERP, API и др.);
* Минимальная или отсутствующая обработка;
* Часто хранится только за короткий период времени;
* Используется для анализа отклонений, аудита и повторной загрузки данных при сбоях.

**Примеры данных:** полные выгрузки из таблиц, лог-файлы, JSON от API, бинарные события и т.п.

---

### 2. **ODS (Operational Data Store)**

**ODS (Операционное хранилище данных)** — это слой, предназначенный для хранения операционных (транзакционных) данных, собранных из различных источников. Этот слой обычно:

**Назначение:**

* Быстрое получение оперативной информации (почти в реальном времени);
* Агрегация и нормализация данных;
* Источник для построения витрин или отчётов в текущем моменте времени.

**Характеристики:**

* Структура ближе к нормализованной форме (3NF);
* Обычно хранится только актуальная информация (без истории);
* Может использоваться в операционных отчётах и дэшбордах.

**Пример:** таблица клиентов из разных систем объединяется по бизнес-ключу, чтобы сформировать единое представление "Клиенты".

---

### 3. **DDS (Data Distribution Store / Data Delivery Store / Data Data Store)**

**DDS** — это аналитический слой хранилища, часто служащий **ядром корпоративного DWH**, и включает в себя **измерения (dimensions)** и **факты (facts)**.

**Назначение:**

* Хранение **историзированных** и **обогащённых** данных;
* Формирование единого аналитического контекста;
* Источник для построения витрин данных, BI-отчётов, аналитических панелей.

**Характеристики:**

* Чаще всего денормализованная структура (звезда или снежинка);
* Используются методы SCD (slowly changing dimensions) для ведения истории;
* Обрабатываются бизнес-правила, трансформации, расчёты.

**Подсистемы DDS:**

* **Факт-таблицы (Fact Tables):** содержат метрики, суммы, счета, транзакции и пр.;
* **Измерения (Dimension Tables):** описательные справочники — клиенты, продукты, время, регионы.

---

### 4. **Data Marts (Витрины данных)**

**Назначение:**

* Предоставление данных для конкретных бизнес-пользователей или подразделений;
* Оптимизированы под отчётность и аналитические запросы.

**Характеристики:**

* Могут быть логическими (в рамках DDS) или физическими (отдельные базы/таблицы);
* Настроены под конкретные задачи: отчёт по продажам, маркетинг, логистика;
* Часто имеют упрощённую модель и агрегированные данные.

---

### 5. **Presentation Layer (слой представления)**

**Назначение:**

* Предоставление доступа к данным конечным пользователям, BI-системам, API и другим внешним компонентам.

**Формы представления:**

* SQL-витрины (views, materialized views);
* OLAP-кубы (например, с использованием ClickHouse, SSAS, Vertica и т.д.);
* Доступ через BI-инструменты (Power BI, Tableau, Looker и пр.);
* REST API или GraphQL интерфейсы для интеграции с другими системами.

---

### 6. **Metadata Layer (слой метаданных)**

**Назначение:**

* Хранение описания данных: источники, типы, владельцы, трансформации, история изменений.

**Используется для:**

* Каталогизации и управления качеством данных;
* Поддержки lineage и data governance;
* Интеграции с Data Catalog системами (например, Apache Atlas, DataHub).

---

### Сводная схема слоёв DWH

```plaintext
[ Источники данных ]
        │
        ▼
[ Staging Area (Raw) ]
        │
        ▼
[ ODS — нормализованные и очищенные данные ]
        │
        ▼
[ DDS — аналитическое ядро (факты + измерения) ]
        │
        ▼
[ Data Marts / BI витрины ]
        │
        ▼
[ Presentation Layer — отчёты, BI, API ]
```

---

### Заключение

Хранилище данных строится по многоуровневой архитектуре, где каждый слой играет важную роль:

* **Staging** — буферизация и приём данных;
* **ODS** — нормализация и консолидация оперативной информации;
* **DDS** — ядро аналитики с историей изменений и бизнес-логикой;
* **Data Marts** — ориентация на конкретных потребителей данных;
* **Presentation** — доступ к данным в удобной форме.

---

## Физические JOINы

Физический джойн — это алгоритм, который используется для выполнения операции объединения двух таблиц. Иными словами, это то, что происходит "под капотом", когда вы вызываете join в запросе

Основных алгоритмов всего 3: nested loops, merge join, hash join/hash match.

### Nested loops

Принцип работы уже понятен из названия: каждый элемент внешнего цикла сравнивается с каждым элементом внутреннего.
Алгоритмическая сложность - O(n**2)

```sql
For Each value in pile1
    For Each value in pile2
        If pile1.value = pile2.value
        Return pile1.value, pile2.value
```
 
### Merge join

Для этого алгоритма элементы уже должны быть отсортированы. Тут мы проходимся двумя указателями по элементам и сравниваем их. В конце проходим по оставшимся элементам.

Если не считать сортировку, алгоритмическая сложность - O(n).

```sql
get first row R1 from   input 1
get first row R2 from   input 2

while not at the end   of either input
      begin
          if R1 joins with R2
              begin
                  get next row R2 from input 2
                  return (R1, R2)
              end
          else if R1 < R2
              get next row R1 from input 1
          else
              get next row R2 from input 2
    end
```

### Hash join

Вычисляем хэш для каждого элемента левой таблицы, затем вычисляем хэш у элементов правой таблицы и проверяем его наличие в левой.
Алгоритмическая сложность - O(n).

```sql
// Build phase
FOR each row in BuildTable DO
    Compute hash value for the join key
    Insert row into HashTable based on hash value
END FOR

// Probe phase
FOR each row in ProbeTable DO
    Compute hash value for the join key
    IF hash value exists in HashTable THEN
        Retrieve matching rows from HashTable
        FOR each matching row DO
            Combine rows from ProbeTable and BuildTable
            Add the combined row to the result set
        END FOR
    END IF
END FOR
```

---

### Выбор физического JOIN

После оценки алгоритмической сложности физических джойнов можно прийти к выводу, что выбор hash join является оптимальным решением, однако это далеко не так. Как и во многом в программировании, всегда есть space–time trade-off (https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%BC%D0%BF%D1%80%D0%BE%D0%BC%D0%B8%D1%81%D1%81_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%B8_%D0%B8_%D0%BF%D0%B0%D0%BC%D1%8F%D1%82%D0%B8), и выбор оптимального джойна будет зависеть от входных данных.

С выбором джойна в большинстве случаев достаточно хорошо справляется оптимизатор, однако бывают ситуации, когда выбором джойна придется заниматься вам.

#### Условие соединения
Для equi-joins (равенство =, неравенство !=) и non-equi-joins (>, <, >=, <=). Для второго типа подойдет только nested loops.

#### Размер таблиц
Также, конечно, важен размер таблиц. Из-за необходимости многократно проходить по второй таблице в случае с nested loops будет велика цена I/O, в случае merge join будет дорогой сортировка, а в случае hash join может не хватить памяти для хеширования, и часть придется переносить на диск. Хешируется, кстати, меньшая таблица.

Если вы работаете с отсортированными данными, выиграет merge join, а с неотсортированными — hash join.

В случае, когда обе таблицы маленькие, эффективнее может быть nested loops, ведь с merge сортировка может вовсе не окупиться.

#### Индексы и дубликаты
В случае с неиндексированными данными лучше справятся merge и hash join, однако наличие большого количества дубликатов при выборе hash join может повлечь неправильное распределение данных и необходимость обработки коллизий.

---

**9. Python: функции, декораторы, ООП и др.**

---

## Лямбда функция (что это, зачем, где использовать)

**Лямбда-функция** — это **анонимная функция**, то есть функция без имени, которая создаётся с помощью ключевого слова `lambda`.

Синтаксис:

```python
lambda аргументы: выражение
```

Пример:

```python
lambda x, y: x + y
```

Этот код создаёт функцию, которая складывает два аргумента `x` и `y`, но не присваивает ей имя. Чтобы использовать её, её можно вызвать напрямую или присвоить переменной:

```python
add = lambda x, y: x + y
print(add(2, 3))  # 5
```

---

### Зачем нужны лямбда-функции?

Лямбда-функции полезны, когда нужно:

1. **Определить простую функцию на месте**, без необходимости выносить её в отдельную именованную функцию.
2. **Сделать код короче и лаконичнее**, особенно когда функция передаётся как аргумент.
3. **Упростить работу с функциями высшего порядка**, такими как `map`, `filter`, `sorted`, `reduce`.

---

### Где использовать лямбда-функции?

Наиболее частые области применения:

1. **В функции `map()`**

```python
numbers = [1, 2, 3, 4]
squares = list(map(lambda x: x ** 2, numbers))
# [1, 4, 9, 16]
```

2. **В функции `filter()`**

```python
numbers = [1, 2, 3, 4, 5]
evens = list(filter(lambda x: x % 2 == 0, numbers))
# [2, 4]
```

3. **В функции `sorted()` с ключом**

```python
data = [('apple', 2), ('banana', 1), ('cherry', 3)]
sorted_data = sorted(data, key=lambda x: x[1])
# [('banana', 1), ('apple', 2), ('cherry', 3)]
```

---

### Ограничения лямбда-функций

* **Только одно выражение** (нельзя писать несколько инструкций или использовать конструкции вроде `if-else` в виде блоков).
* **Сложность в отладке**, особенно при большом количестве вложенных лямбда-функций.
* **Не всегда читаемо**, особенно для менее опытных разработчиков.

---

### Когда **не стоит** использовать лямбда-функции

* Если функция сложная или многострочная — лучше использовать `def`, чтобы улучшить читаемость.
* Если требуется повторное использование — именованная функция будет понятнее.

---

В Python операторы `==` и `is` используются для **сравнения**, но делают это по-разному и применяются в разных случаях. Вот подробное объяснение различий:

---

## В чем разница "==" и "is"?

### `==` — оператор **сравнения значений**

Оператор `==` проверяет, **равны ли значения** двух объектов, то есть **имеют ли они одинаковое содержимое**.

**Пример**:

```python
a = [1, 2, 3]
b = [1, 2, 3]

print(a == b)  # True — списки имеют одинаковое содержимое
```

Здесь `a` и `b` — это **два разных объекта в памяти**, но их значения совпадают, поэтому `==` возвращает `True`.

---

### `is` — оператор **сравнения идентичности объектов**

Оператор `is` проверяет, **являются ли два объекта на самом деле одним и тем же объектом в памяти**, то есть указывают ли они на **одну и ту же ячейку памяти (один и тот же ID)**.

**Пример**:

```python
a = [1, 2, 3]
b = [1, 2, 3]

print(a is b)  # False — это два разных объекта

c = a
print(a is c)  # True — это один и тот же объект
```

---

### Сравнение в таблице

| Критерий                    | `==` (равенство значений)              | `is` (идентичность объектов)                       |
| --------------------------- | -------------------------------------- | -------------------------------------------------- |
| Что сравнивает              | Содержимое объектов                    | Адреса объектов в памяти (id)                      |
| Может вернуть `True` для... | Разных объектов с одинаковым значением | Только для одного и того же объекта                |
| Пример с числами            | `1000 == 1000 → True`                  | `1000 is 1000 → False` (может быть)                |
| Применение                  | Проверка логического равенства         | Проверка, указывает ли переменная на тот же объект |

---

### Особенности и исключения

1. **Интернирование (interning)**

Python оптимизирует хранение некоторых объектов, таких как **небольшие целые числа** и **строки**, создавая их один раз и повторно используя (интернирование). Поэтому `is` может вернуть `True` даже для на первый взгляд разных переменных.

```python
a = 10
b = 10
print(a is b)  # True — Python использует один и тот же объект

x = 1000
y = 1000
print(x is y)  # False — объекты могут быть разными
```

Поведение зависит от реализации интерпретатора и может отличаться.

2. **Сравнение с `None`**

Сравнение с `None` **всегда** следует делать через `is`, а не `==`.

```python
if value is None:
    ...
```

Потому что `None` — это **одиночный объект**, и `is` проверяет его идентичность корректно.

---

## В чем разница между `func` и `func()`?

Разница между `func` и `func()` в Python принципиальная, и она связана с тем, что в одном случае мы работаем с **ссылкой на функцию**, а в другом — **вызываем эту функцию**.

---

### `func` — это **объект функции** (ссылка на неё)

Когда пишем `func`, без скобок, мы **не вызываем** функцию. Вместо этого мы **ссылаемся на сам объект функции**. Это позволяет, например, передать её как аргумент в другую функцию, сохранить в переменной или вызвать позже.

**Пример**:

```python
def greet():
    return "Hello"

a = greet      # просто ссылка на функцию
print(a)       # <function greet at 0x...>
print(a())     # Hello — вызов через переменную
```

Здесь:

* `a = greet` — сохраняет ссылку на функцию.
* `a()` — вызывает функцию через переменную.

---

### `func()` — это **вызов функции**

Когда пишем `func()`, мы **вызываем** функцию `func`. То есть Python:

1. Выполняет код внутри этой функции,
2. Возвращает результат (если есть оператор `return`),
3. Выполняет побочные эффекты, если они есть (например, печать в консоль, запись в файл и т.д.).

**Пример**:

```python
def greet():
    print("Hello")

greet      # ничего не происходит
greet()    # выводит "Hello"
```

---

### Сравнение:

| Выражение | Что означает      | Что делает                          |
| --------- | ----------------- | ----------------------------------- |
| `func`    | Ссылка на функцию | Ничего не вызывает, можно сохранить |
| `func()`  | Вызов функции     | Запускает функцию                   |

---

### Где важно различие:

1. **Передача функции как аргумента**

```python
def executor(callback):
    return callback()

def say_hi():
    return "Hi"

executor(say_hi)    # передаём функцию — правильно
executor(say_hi())  # передаём результат вызова — ошибка, если результат не функция
```

2. **Создание отложенных вычислений**

```python
actions = [lambda: 2 + 2, lambda: 3 * 3]

for action in actions:
    print(action())  # вызываем каждый элемент списка
```

---

## Назовите изменяемые и неизменяемые объекты (типы).

### Изменяемые объекты (mutable)

Изменяемые объекты — это такие, **состояние которых можно изменить после создания**, не меняя их идентификатор (`id` в памяти).

**Примеры** изменяемых объектов:

| Тип                                    | Пример              | Описание                                     |
| -------------------------------------- | ------------------- | -------------------------------------------- |
| `list`                                 | `[1, 2, 3]`         | Можно добавлять, удалять и изменять элементы |
| `dict`                                 | `{"a": 1}`          | Можно менять значения по ключу               |
| `set`                                  | `{1, 2, 3}`         | Можно добавлять и удалять элементы           |
| `bytearray`                            | `bytearray(b"abc")` | Побайтово изменяемая версия `bytes`          |
| Пользовательские классы (по умолчанию) | `class A: pass`     | Объекты можно менять через атрибуты          |

**Пример**:

```python
lst = [1, 2, 3]
lst[0] = 100
print(lst)  # [100, 2, 3]
```

---

### Неизменяемые объекты (immutable)

Неизменяемые объекты — это такие, **состояние которых нельзя изменить после создания**. Любая попытка изменить их приводит к созданию **нового объекта** в памяти.

**Примеры** неизменяемых объектов:

| Тип         | Пример              | Описание                                       |
| ----------- | ------------------- | ---------------------------------------------- |
| `int`       | `42`                | Любое изменение создаёт новый объект           |
| `float`     | `3.14`              | Аналогично с `int`                             |
| `str`       | `"hello"`           | Изменить символы строки нельзя                 |
| `tuple`     | `(1, 2, 3)`         | Но: может содержать изменяемые элементы внутри |
| `frozenset` | `frozenset([1, 2])` | Неизменяемая версия множества                  |
| `bytes`     | `b"abc"`            | Неизменяемая побайтовая строка                 |
| `bool`      | `True`, `False`     | Подвид `int`, тоже неизменяемый                |
| `NoneType`  | `None`              | Единственный экземпляр                         |

**Пример**:

```python
a = "hello"
print(id(a))          # допустим, 140730
a = a.upper()
print(id(a))          # другой id, т.к. создан новый объект
```

---

###Как проверить, изменяем объект или нет?

Попробуйте изменить его содержимое напрямую или использовать `id()`:

```python
x = (1, 2, 3)
print(id(x))
x = (1, 2, 3, 4)
print(id(x))  # id изменится — новый объект
```

---

### Сравнение изменяемых и неизменяемых:

| Свойство                             | Изменяемые объекты                     | Неизменяемые объекты    |
| ------------------------------------ | -------------------------------------- | ----------------------- |
| Можно менять после создания          | Да                                     | Нет                     |
| `id(obj)` при изменении              | Не меняется                            | Меняется (новый объект) |
| Можно использовать как ключ в `dict` | Нет (если объект сам по себе изменяем) | Да                      |
| Безопасность при многопоточности     | Менее безопасны                        | Более безопасны         |

---

### Вложенные структуры

Некоторые **неизменяемые объекты могут содержать изменяемые внутри**:

```python
t = (1, [2, 3])
t[1][0] = 99
print(t)  # (1, [99, 3]) — tuple сам неизменяем, но содержит изменяемый список
```

---

## Декораторы (что, зачем нужно, как влияет на структуру) + написать свой пример









---

## Источники

https://t.me/data_interviews
