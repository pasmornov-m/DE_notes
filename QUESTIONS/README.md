# QUESTIONS

---

## **1. Хранилища данных (DWH, Data Lake, архитектура)**

* [Какие подходы построения хранилища данных тебе известны?](#подходы-построения-хранилища-данных)
* [Чем Data Lake отличается от DWH?](#чем-data-lake-отличается-от-dwh)
* [В чем разница подходов Кимболла и Инмона?](#разница-между-подходами-кимболла-и-инмона)
* [Расскажи, что знаешь про SCD?](#scd-slowly-changing-dimensions)
* [Как сформировать процесс SCD2 для вставки, изменения, удаления?](#как-реализовать-scd-type-2-на-примере-клиентов)
* [Как правильно работать с таблицами, если 1я — это просто справочник (например, пользователи) построенный по SCD2, а 2я — это покупки пользователей, и необходимо найти все покупки пользователя с актуальными данными на день покупки.](#как-правильно-работать-с-таблицами-если-1я--это-просто-справочник-например-пользователи-построенный-по-scd2-а-2я--это-покупки-пользователей-и-необходимо-найти-все-покупки-пользователя-с-актуальными-данными-на-день-покупки)
* [Расскажи какие слои есть в хранилище данных?](#слои-в-хранилище-данных)
* [Чем в хранилище ODS слой отличается от DDS слоя?](#слои-в-хранилище-данных)

---

## **2. HDFS, Hadoop, Spark, Hive, Oozie, YARN**

* Что такое HDFS? Из чего она состоит и как работает?
* Какие проблемы бывают с HDFS?
* Что такое перекос данных?
* Как работает HSFD? Для чего нужна NameNode, Secondary NameNode? Нам необходимо считать текстовый файл из HDFS, объясни, что будет происходить?
* Что такое фактор репликации в HDFS и для чего он нужен?
* Что такое Hadoop и из каких компонентов он состоит?
* Что такое YARN?
* Для чего нужен Apache Oozie?
* Что такое Hive и объясни, как он работает с данными?
* Для чего нужен Hive?
* Что такое партиционирование и что оно из себя представляет в Hadoop?
* Что такое Spark? Для чего она нужна?
* Что делает Shuffle в Spark? Между чем передаются данные?
* Объясни парадигму MapReduce и почему Spark пришел ей на замену?
* Какие виды exchange (motion) в Spark?
* Как передать UDF?

---

## **3. ClickHouse**

* Какие движки ClickHouse вы знаете?
* Какие особенности у движка ReplicatingMergeTree?
* Представь у тебя есть PGSQL и ClickHouse, как бы ты загружал данные из PGSQL в ClickHouse?
* Тебе необходимо из источника отправлять данные в нейронку каждые 10 минут, после чего результат записывать в ClickHouse, как ты это сделаешь? Опиши весь процесс.
* Как создать распределенную таблицу в Clickhouse?
* Какие движки в ClickHouse ты знаешь? И в чем их различия?
* Как оптимизировать запросы в Clickhouse?
* Как в Clickhouse устроена операция UPDATE?

---

## **4. Greenplum**

* В чем различие между GreenPlum и HDFS?
* Как происходит оптимизация запросов в GreenPlum?
* Для каких целей преднозначен Clickhouse и GreenPlum?

---

## **5. SQL, оконные функции, индексы, joins, СТЕ и др.**

* Что такое оконные функции?
* Как задать границы окна?
* В чем будет разница вывода, если я напишу агрегирующую оконную функцию по сумме с сортировкой и без неё?
* Представим что DENSE_RANK не существует, как сделать её функционал с помощью ROW_NUMBER?
* Чем отличается DENSE_RANK от RANK?
* Какие физические виды Join знаете?
* Что делает утилита PGTune?
* Что такое нормализация?
* Какие типы индексов бывают?
* Чем отличается кластеризованный индекс от некластеризованного?
* Сколько у таблицы может быть кластеризованных индексов?
* Есть ли ограничения на создание партицированной таблицы?
* Можно ли строить индекс по JSON полям?
* Чем отличаются типы данных JSON и JSONb?
* Чем отличаются материализованное и нематериализованное представления?
* Можно ли читать данные из материализованного представления, когда выполняется команда REFRESH?
* Как удалить дубликаты из таблицы?
* Как эффективно удалить дубликаты строк в большой таблице?
* Какой объявить СТЕ? Можно ли в одной таблице применить несколько СТЕ?
* Что из себя представляет СТЕ?
* Как оптимизируется запрос?
* Что будет делать, если в плане запроса увидели Nested Loop?
* Расскажи всё, что знаешь об индексах?
* Чем колоночные БД отличаются от строковых?

---

## **6. PostgreSQL (PGSQL)**

* Как выдаются права доступа в PostgreSQL?
* Как устроена система транзакций в PSQL?
* Какие блокировки существуют?

---

## **7. Apache NiFi**

* Какие процессоры использовали в NiFi?
* Настраивали ли схемы, если да, то в каких модулях?
* Как считать данные из каталога?
* Зачем при считывании CSV файлов данные переводили в AVRO формат?
* В случае сбоя одного сервера с NiFi — как его перезапустить?
* Чем Атрибут отличается от Контекста?
* Теряет ли данные NiFi, если произошел сбой программы?
* Расскажи о логировании в NiFi?
* Какой модуль в NiFi используется для JOLT преобразований?
* NiFi работает в кластере и считываем данные из Kafka, один из серверов сгорает, и мы теряем данные. Как повторно обработать потерянные данные?

---

## **8. Apache Airflow**

* Таска в AirFlow упала с ошибкой, как сделать так, чтобы несмотря на ошибку, следующая таска запустилась?
* Как в AirFlow в зависимости от условия, продолжить обработку по нужной ветке ДАГа?

---

## **9. Python: функции, декораторы, ООП и др.**

* Лямбда функция (что это, зачем, где использовать)
* Назовите парадигмы ООП?
* В чем разница "==" и "is"?
* Self (что это, для чего нужен, как и где использовать)
* В чем разница между `func` и `func()`?
* Назовите изменяемые и неизменяемые объекты.
* Декораторы (что, зачем нужно, как влияет на структуру) + написать свой пример
* Можно ли на одну функцию нацепить несколько декораторов и как они будут считываться?
* Функция, которая используется в качестве аргумента, может использовать свои аргументы?
* Что такое декоратор Шредингера?
* Как записывается декоратор?
* Генератор (что, зачем нужно) + написать свой пример
* Как рассчитывается сложность алгоритма? на примере list, tuple
* Как передаются аргументы в функцию?
* Зачем прописывать тип входящих или выходящих данных в функцию?
* Что такое super() и зачем нужен?
* Что такое итерация?
* Расскажи порядок разрешения методов?
* Что представляет из себя тип данных Int в Python?
* Какая типизация используется в Python?
* Можно ли в функции Python в качестве аргумента использовать функцию? Если да, то как называется такая функция?

---

# ANSWERS

---

## Подходы построения хранилища данных

### 1. Top-down (по Инмону)

#### Суть:

* Подход предполагает **централизованную архитектуру**, при которой в первую очередь создаётся **Enterprise Data Warehouse (EDW)** — единое корпоративное хранилище данных.
* Это хранилище содержит **нормализованные** данные (обычно 3NF), структурированные по предметным областям.

#### Особенности:

* EDW служит **единственным источником правды (Single Source of Truth)**.
* Из EDW создаются **витрины данных (Data Marts)**, уже в денормализованной форме — под нужды конкретных бизнес-пользователей или аналитиков.
* Основной акцент — **качество, консистентность, историчность**.

#### Плюсы:

* Централизованное управление метаданными и качеством данных.
* Удобно масштабировать и сопровождать на уровне всей организации.

#### Минусы:

* Высокая **стоимость и длительность внедрения**.
* Сложность в адаптации к изменяющимся бизнес-требованиям.

---

### 2. Bottom-up (по Кимболлу)

#### Суть:

* Построение хранилища начинается **с витрин данных (Data Marts)**, создаваемых для отдельных бизнес-процессов.
* Позже эти витрины объединяются в **логическое DWH**.

#### Особенности:

* Используется **денормализованная схема**, чаще всего **звезда** (star schema) или **снежинка** (snowflake).
* Данные моделируются вокруг **факт-таблиц** и **измерений**.
* Популярен благодаря своей **простоте и быстрому Time-to-Market**.

#### Плюсы:

* Быстрое получение бизнес-результатов.
* Относительно просто обучить и подключить конечных пользователей.
* Хорошая производительность при аналитических запросах.

#### Минусы:

* При масштабировании и объединении множества витрин возможно **дублирование логики**, **расхождение метрик**.
* Нет единого централизованного источника правды.

---

### 3. Data Vault

#### Суть:

* **Гибридный подход**, сочетающий достоинства Инмона и Кимболла.
* Разделяет структуру на **Hub (ключи сущностей)**, **Link (связи между сущностями)** и **Satellite (атрибуты, историчность)**.

#### Особенности:

* Поддерживает **историчность**, **аудит**, **многоверсионность**.
* Хорошо подходит для **Agile и DevOps** сред.
* Логика бизнес-преобразования вынесена за пределы core-структуры — в **Data Marts**.

#### Плюсы:

* Легко масштабируется и адаптируется под изменения схем источников.
* Строго отделяет бизнес-логику от данных.
* Хорошо подходит для **Big Data и распределённых систем**.

#### Минусы:

* Более **сложная модель**, требует грамотной ETL-реализации.
* Сложность в прямой аналитике без промежуточной агрегации.

---

### 4. Data Lake

#### Суть:

* Хранилище **сырого или полуобработанного** контента в виде файлов, таблиц, изображений и пр.
* Как правило, работает на базе **объектного хранилища**: S3, HDFS, Azure Blob.

#### Особенности:

* Используется в основном для **Big Data** и **Data Science** задач.
* Структура данных может быть **semi-structured** или **unstructured** (JSON, Parquet, Avro и пр.).
* Отложенная обработка (ELT, а не ETL).

#### Плюсы:

* Дешёвое масштабируемое хранилище.
* Гибкость в использовании — можно применять машинное обучение, потоковую обработку и пр.
* Подходит для хранения **огромных объёмов** разнотипных данных.

#### Минусы:

* Отсутствие схемы ведёт к **хаосу и "data swamp"**, если не настроены правила и метаданные.
* Сложнее обеспечить консистентность и управление качеством данных.

---

### 5. Lakehouse

#### Суть:

* Современный гибрид **Data Lake + Data Warehouse**.
* Использует движки вроде **Delta Lake**, **Apache Iceberg**, **Apache Hudi**, которые дают поддержку **ACID**, **time-travel**, **схем**, **индексов** и пр. поверх Data Lake.

#### Особенности:

* Хранение осуществляется в файловой системе, но с возможностями реляционной обработки.
* Работает с теми же инструментами, что и Data Lake (Spark, Presto, Dremio и др.).

#### Плюсы:

* Объединяет гибкость Data Lake с управляемостью DWH.
* Позволяет строить BI-отчёты и Data Science на одних и тех же данных.
* Хорошая производительность и контроль данных.

#### Минусы:

* Пока что менее зрелая технология, требует интеграции нескольких компонентов.
* Не всегда просто настраивается без облачных платформ (Databricks, Snowflake).

---

### 6. Lambda и Kappa архитектуры

#### Lambda Architecture:

* Объединяет **batch processing** (например, Hadoop/Spark) и **stream processing** (Kafka/Storm/Flink).
* Данные сначала обрабатываются в реальном времени (speed layer), а потом — партиями для точности (batch layer).
* Используется при требовании **быстрых и точных данных одновременно**.

#### Kappa Architecture:

* Упрощённая архитектура, в которой **все данные обрабатываются как поток**.
* Нет разделения на batch и stream — единый pipeline.

#### Плюсы:

* Lambda: высокая точность и скорость.
* Kappa: простота архитектуры, лучше подходит для событийных систем.

#### Минусы:

* Lambda: высокая сложность поддержки двух параллельных путей обработки.
* Kappa: сложнее корректировать ошибки в исторических данных.

---

**Заключение**:

Инмон и Кимболл — классические для BI, Data Vault — для гибкости и историчности, Data Lake и Lakehouse — для современных Big Data и ML-задач.

---

## Чем Data Lake отличается от DWH?

### 1. **Тип хранимых данных**

* **DWH (Data Warehouse):**

  * Хранит **структурированные данные** из различных источников, которые предварительно очищаются и трансформируются.
  * Используются реляционные базы данных, таблицы с жёстко заданными схемами.

* **Data Lake:**

  * Может хранить **любой тип данных**: структурированные (таблицы), полуструктурированные (JSON, XML), неструктурированные (изображения, видео, логи).
  * Данные загружаются "как есть", без строгой предварительной обработки (raw format).

---

### 2. **Схема и структура хранения**

* **DWH:**

  * Использует подход **schema-on-write** — данные приводятся к чёткой структуре **до** записи в хранилище.
  * Модель хранения разрабатывается заранее (звезда, снежинка, 3NF).

* **Data Lake:**

  * Использует подход **schema-on-read** — данные приводятся к нужной структуре **только во время чтения**.
  * Возможна работа с данными без заранее заданной схемы.

---

### 3. **Назначение**

* **DWH:**

  * Предназначено для **аналитики и бизнес-отчётности**.
  * Чётко определённые источники данных, высокая точность и надёжность.

* **Data Lake:**

  * Используется для **анализа больших объёмов разнородных данных**, в том числе для **Data Science**, **машинного обучения**, **потоковой обработки**.
  * Часто служит как единое хранилище "сырых" данных.

---

### 4. **Процесс загрузки данных**

* **DWH:**

  * Применяется классическая **ETL (Extract → Transform → Load)** схема: сначала данные очищаются и трансформируются, потом загружаются в хранилище.
* **Data Lake:**

  * Применяется **ELT (Extract → Load → Transform)**: данные сначала загружаются в lake, а потом обрабатываются по мере необходимости.

---

### 5. **Хранилище и технологии**

* **DWH:**

  * Обычно реализовано на **реляционных базах данных** (PostgreSQL, Oracle, Greenplum, Snowflake, MS SQL).
  * Поддерживает SQL-запросы и индексацию.

* **Data Lake:**

  * Строится на **объектных хранилищах** (Amazon S3, HDFS, Azure Blob).
  * Поддерживает работу с файлами (Parquet, ORC, Avro) и распределённую обработку (Spark, Presto, Flink).

---

### 6. **Гибкость и масштабируемость**

* **DWH:**

  * Ограничен типом данных и объёмами. Масштабируемость требует вертикального роста (более мощное железо).
  * Высокие требования к качеству и консистентности.

* **Data Lake:**

  * Гибок, масштабируется горизонтально. Подходит для хранения **петабайтов данных**.
  * Часто используется в **облачных инфраструктурах**.

---

### 7. **Стоимость**

* **DWH:**

  * Дороже в разработке и сопровождении, так как требует проектирования схем, ETL-процессов, инфраструктуры.

* **Data Lake:**

  * Относительно дешевле, особенно при использовании облачных решений. Не требует сложной подготовки данных перед загрузкой.


Оба подхода могут использоваться **совместно**, например: данные сначала собираются в Data Lake, затем после очистки и агрегации загружаются в DWH для бизнес-анализа. Такой гибридный подход особенно популярен в больших компаниях.

---

## Разница между подходами Кимболла и Инмона

Заключается в архитектуре построения хранилищ данных, способе организации данных, приоритетах и применении нормализации. Ниже подробно раскрыты основные различия между двумя подходами.

---

### 1. **Общий подход к построению хранилища**

**Инмон**:

* Считается «отцом корпоративного хранилища данных (EDW)».
* Подход **top-down** — сначала проектируется **централизованное хранилище**, потом на его основе строятся витрины данных для отдельных бизнес-подразделений.
* Основное внимание уделяется **централизованности и согласованности** данных.

**Кимболл**:

* Подход **bottom-up** — сначала создаются **витрины данных (Data Marts)** под конкретные бизнес-задачи, которые затем объединяются в единое логическое хранилище.
* Основной приоритет — **быстрое удовлетворение потребностей бизнеса**, простота реализации.

---

### 2. **Моделирование данных**

**Инмон**:

* Используется **нормализованная структура**, чаще всего **третья нормальная форма (3NF)**.
* Данные хранятся в виде **предметно-ориентированных таблиц**, связанных друг с другом через ключи.
* Цель — устранение избыточности, повышение целостности данных.

**Кимболл**:

* Используются **денормализованные структуры**, в частности **звёздная схема (star schema)** или **снежинка (snowflake schema)**.
* Основные сущности: **факт-таблицы** (события, числовые показатели) и **измерения** (атрибуты сущностей).
* Цель — обеспечить удобство и производительность аналитических запросов.

---

### 3. **Порядок загрузки и обработки данных**

**Инмон**:

* Используется классическая схема **ETL (Extract – Transform – Load)**.
* Данные сначала приводятся к строгой структуре, очищаются, нормализуются, а затем загружаются в хранилище.
* Требует тщательной подготовки и согласования схем.

**Кимболл**:

* Может использовать **ETL** или **ELT**, но основная задача — быстро и удобно представить данные бизнес-пользователям.
* Трансформации выполняются так, чтобы обеспечить удобство построения отчётов и анализа.

---

### 4. **Инфраструктура и масштабируемость**

**Инмон**:

* Предполагает создание **единого корпоративного хранилища**, которое служит универсальным источником данных для всех подразделений.
* Хорошо подходит для **больших организаций** с высокими требованиями к качеству данных и контролю.

**Кимболл**:

* Строится из **наборов независимых витрин**, каждая из которых разрабатывается быстро под конкретную задачу.
* Легче начать внедрение в условиях ограниченных ресурсов или при необходимости быстрого результата.

---

### 5. **Гибкость и сопровождение**

**Инмон**:

* **Менее гибкий**: изменение структуры требует серьёзных доработок в централизованной модели.
* Зато обеспечивает **долгосрочную устойчивость**, согласованность и прозрачность структуры данных.

**Кимболл**:

* **Более гибкий**: легко создавать и модифицировать витрины, адаптируя под новые задачи.
* При масштабировании и объединении витрин может возникнуть **дублирование данных и логики**.

---

### 6. **Пользователи и цели**

**Инмон**:

* Ориентирован на **ИТ-отделы и архитекторов**, строится с учётом стратегических целей и корпоративных требований.
* Часто используется в системах, где важна **аудитность, безопасность, соответствие нормативам**.

**Кимболл**:

* Ориентирован на **бизнес-пользователей и аналитиков**, которым нужны простые отчёты и быстрая аналитика.
* Хорошо подходит для **BI-инструментов** и визуализации данных.

---

### 7. **Примеры применения**

* **Инмон** — крупные организации, банки, телеком, госсектор, где важна высокая целостность и долгосрочная архитектура.
* **Кимболл** — небольшие и средние компании, или команды, которым нужно быстрое внедрение BI.

---

### Заключение

Подход Инмона подходит для создания масштабируемой, надёжной архитектуры, с акцентом на качество и контроль данных. Подход Кимболла — для быстрого внедрения аналитики и адаптивности к изменяющимся требованиям бизнеса.

На практике часто применяются **гибридные подходы**, где корпоративное хранилище проектируется по Инмону, а витрины — по Кимболлу. Это позволяет сочетать централизованность с удобством анализа.

---

## SCD (Slowly Changing Dimensions)

### Что такое SCD?

**SCD (медленно изменяющиеся измерения)** — это справочные таблицы (например, клиенты, продукты, сотрудники), данные в которых изменяются **редко**, но такие изменения необходимо **хранить** и учитывать в аналитике. Например, клиент сменил адрес или должность, и важно понимать, как его поведение или метрики менялись до и после этого события.

---

### Основные типы SCD

#### **SCD Type 0 — неизменяемые измерения**

* Данные в таблице **никогда не изменяются** после загрузки.
* Используется для атрибутов, которые не должны пересматриваться (например, дата рождения).
* Любое изменение источника игнорируется.

**Применение:** паспортные данные, пол, дата рождения.

---

#### **SCD Type 1 — перезапись (overwrite)**

* Изменения **перезаписываются**: старое значение теряется, хранится только актуальное.
* Простой в реализации, но не даёт возможности проанализировать прошлое значение.

**Пример:** клиент сменил город — в таблице просто обновляется значение поля `city`.

**Плюсы:** простая реализация, экономит место.
**Минусы:** невозможно восстановить историю изменений.

---

#### **SCD Type 2 — хранение полной истории изменений**

* Каждое изменение приводит к **созданию новой строки** в таблице.
* Используются специальные поля:

  * `valid_from` / `valid_to` (период действия записи),
  * `is_current` (флаг актуальности),
  * `version` (опционально).

**Пример:** при смене адреса у клиента будет две строки: одна с прошлым адресом, другая — с новым, и только одна из них будет помечена как текущая.

**Плюсы:** можно проводить анализ в ретроспективе, отслеживать, когда и какие изменения происходили.
**Минусы:** большее потребление памяти, усложнённая логика работы.

---

#### **SCD Type 3 — хранение части истории**

* Хранится только **одно предыдущее значение** вместе с текущим (например, `previous_city`, `current_city`).
* Подходит, когда не требуется глубокая история изменений.

**Пример:** для клиента можно хранить текущий и предыдущий адрес, но не более.

**Плюсы:** экономия места.
**Минусы:** ограниченная аналитическая ценность, невозможно отследить более двух состояний.

---

### Другие типы (используемые реже):

#### SCD Type 4 — журнал изменений (Change History Table)

* История хранится **в отдельной таблице**, а основная справочная содержит только актуальные данные.
* Используется для минимизации нагрузки на основную таблицу и для удобной работы с историей.

#### SCD Type 6 — гибрид 1+2+3

* Сочетает сразу несколько стратегий:

  * перезапись текущих значений (как Type 1),
  * хранение истории в виде новых строк (как Type 2),
  * сохранение предыдущего значения в колонке (как Type 3).
* Применяется в системах с высокими требованиями к аналитике.

---

### Зачем нужен SCD?

* Для корректного анализа данных во времени.
* Чтобы избежать искажений в отчётах при изменении справочной информации.
* Для соответствия требованиям аудита и нормативного учёта (например, в банковской или медицинской сфере).

---

### Технические аспекты:

* Важно использовать **бизнес-ключи**, а не surrogate-ключи (primary key), для определения изменений.
* Для Type 2 часто добавляют поля:

  * `surrogate_key` (уникальный ID строки),
  * `valid_from`, `valid_to`,
  * `version`,
  * `is_current`.


---

### Как реализовать SCD Type 2 (на примере клиентов):

Обработка включает три сценария: **вставка новой записи**, **изменение существующей записи** и **обработка удаления**.

#### 1. **Вставка новой записи (insert)**

Если в целевой таблице нет строки с таким `business_key` (например, `customer_id`):

* Вставить новую строку с:

  * `valid_from = now()`
  * `valid_to = NULL`
  * `is_current = true`
  * другими полями, соответствующими входным данным.

---

#### 2. **Изменение существующей записи (update)**

Если запись с `business_key` существует и флаг `is_current = true`, нужно проверить: изменились ли **отслеживаемые** атрибуты (например, адрес, должность и т.д.):

* **Если атрибуты изменились:**

  * Завершить старую запись:

    * `valid_to = now()`
    * `is_current = false`
  * Вставить новую строку:

    * `valid_from = now()`
    * `valid_to = NULL`
    * `is_current = true`
    * с обновлёнными значениями полей.

* **Если изменений нет:**

  * Ничего не делать (данные актуальны, история не нарушается).

---

#### 3. **Удаление записи (delete / логическое удаление)**

Удаления в SCD2 обычно не означают физическое удаление строки, а оформляются как **завершение действия записи**:

* Найти текущую активную запись (`is_current = true`);
* Обновить:

  * `valid_to = now()`
  * `is_current = false`
* (Опционально) добавить логическое поле `is_deleted = true` в новую запись, если требуется отражение удаления.

**Важно:** Если необходимо вести учёт «удалённых» записей (например, клиент ушёл), можно создать новую строку с тем же `business_key`, но с флагом `is_deleted = true`, чтобы сохранялась история.

---

### Как правильно работать с таблицами, если 1я — это просто справочник (например, пользователи) построенный по SCD2, а 2я — это покупки пользователей, и необходимо найти все покупки пользователя с актуальными данными на день покупки.

#### Условия задачи

* **Таблица `users_scd2`** — справочник пользователей, ведётся по SCD Type 2, содержит:

  * `user_id` — бизнес-ключ (natural key);
  * `valid_from` и `valid_to` — диапазон действия версии;
  * `is_current` — флаг актуальности;
  * другие атрибуты (например, `user_city`, `user_status` и т.д.).

* **Таблица `purchases`** — факт-покупки:

  * `user_id` — внешний ключ на пользователя;
  * `purchase_date` — дата покупки;
  * другие атрибуты (сумма, товар и т.д.).

---

#### Цель

Найти все покупки пользователей, при этом — к каждой покупке прикрепить актуальную на **дату покупки** версию пользователя из таблицы `users_scd2`.

---

#### Правильный подход

Для этого выполняется **темпоральное соединение (range join)** по следующему условию:

```sql
purchases.user_id = users_scd2.user_id
AND purchases.purchase_date >= users_scd2.valid_from
AND (purchases.purchase_date < users_scd2.valid_to OR users_scd2.valid_to IS NULL)
```

---

## Пример SQL-запроса

```sql
SELECT
    p.purchase_id,
    p.user_id,
    p.purchase_date,
    p.amount,
    u.user_city,
    u.user_status
FROM
    purchases p
JOIN
    users_scd2 u
    ON p.user_id = u.user_id
   AND p.purchase_date >= u.valid_from
   AND (p.purchase_date < u.valid_to OR u.valid_to IS NULL);
```

---

## Объяснение условий

* `p.user_id = u.user_id` — обычное соединение по бизнес-ключу;
* `p.purchase_date >= u.valid_from` — дата покупки должна быть позже начала действия версии;
* `p.purchase_date < u.valid_to OR u.valid_to IS NULL` — покупка произошла до конца действия версии, или же версия ещё актуальна (в этом случае `valid_to` = `NULL`).

Таким образом, к каждой покупке будет привязана именно **та версия пользователя**, которая была действующей в момент совершения этой покупки.

---

## Слои в хранилище данных

Хранилище данных (Data Warehouse, DWH) строится по **многоуровневой архитектуре**, где каждый слой выполняет свою специфическую задачу и служит промежуточным этапом обработки данных. Это позволяет обеспечить надёжность, масштабируемость и упрощает сопровождение системы.

---

### 1. **Staging Area (или Raw/Buffer Layer)**

**Назначение:** временное хранилище "сырых" данных, загружаемых из источников.
**Характеристики:**

* Данные поступают в том виде, в котором они есть в источниках (CRM, ERP, API и др.);
* Минимальная или отсутствующая обработка;
* Часто хранится только за короткий период времени;
* Используется для анализа отклонений, аудита и повторной загрузки данных при сбоях.

**Примеры данных:** полные выгрузки из таблиц, лог-файлы, JSON от API, бинарные события и т.п.

---

### 2. **ODS (Operational Data Store)**

**ODS (Операционное хранилище данных)** — это слой, предназначенный для хранения операционных (транзакционных) данных, собранных из различных источников. Этот слой обычно:

**Назначение:**

* Быстрое получение оперативной информации (почти в реальном времени);
* Агрегация и нормализация данных;
* Источник для построения витрин или отчётов в текущем моменте времени.

**Характеристики:**

* Структура ближе к нормализованной форме (3NF);
* Обычно хранится только актуальная информация (без истории);
* Может использоваться в операционных отчётах и дэшбордах.

**Пример:** таблица клиентов из разных систем объединяется по бизнес-ключу, чтобы сформировать единое представление "Клиенты".

---

### 3. **DDS (Data Distribution Store / Data Delivery Store / Data Data Store)**

**DDS** — это аналитический слой хранилища, часто служащий **ядром корпоративного DWH**, и включает в себя **измерения (dimensions)** и **факты (facts)**.

**Назначение:**

* Хранение **историзированных** и **обогащённых** данных;
* Формирование единого аналитического контекста;
* Источник для построения витрин данных, BI-отчётов, аналитических панелей.

**Характеристики:**

* Чаще всего денормализованная структура (звезда или снежинка);
* Используются методы SCD (slowly changing dimensions) для ведения истории;
* Обрабатываются бизнес-правила, трансформации, расчёты.

**Подсистемы DDS:**

* **Факт-таблицы (Fact Tables):** содержат метрики, суммы, счета, транзакции и пр.;
* **Измерения (Dimension Tables):** описательные справочники — клиенты, продукты, время, регионы.

---

### 4. **Data Marts (Витрины данных)**

**Назначение:**

* Предоставление данных для конкретных бизнес-пользователей или подразделений;
* Оптимизированы под отчётность и аналитические запросы.

**Характеристики:**

* Могут быть логическими (в рамках DDS) или физическими (отдельные базы/таблицы);
* Настроены под конкретные задачи: отчёт по продажам, маркетинг, логистика;
* Часто имеют упрощённую модель и агрегированные данные.

---

### 5. **Presentation Layer (слой представления)**

**Назначение:**

* Предоставление доступа к данным конечным пользователям, BI-системам, API и другим внешним компонентам.

**Формы представления:**

* SQL-витрины (views, materialized views);
* OLAP-кубы (например, с использованием ClickHouse, SSAS, Vertica и т.д.);
* Доступ через BI-инструменты (Power BI, Tableau, Looker и пр.);
* REST API или GraphQL интерфейсы для интеграции с другими системами.

---

### 6. **Metadata Layer (слой метаданных)**

**Назначение:**

* Хранение описания данных: источники, типы, владельцы, трансформации, история изменений.

**Используется для:**

* Каталогизации и управления качеством данных;
* Поддержки lineage и data governance;
* Интеграции с Data Catalog системами (например, Apache Atlas, DataHub).

---

### Сводная схема слоёв DWH

```plaintext
[ Источники данных ]
        │
        ▼
[ Staging Area (Raw) ]
        │
        ▼
[ ODS — нормализованные и очищенные данные ]
        │
        ▼
[ DDS — аналитическое ядро (факты + измерения) ]
        │
        ▼
[ Data Marts / BI витрины ]
        │
        ▼
[ Presentation Layer — отчёты, BI, API ]
```

---

### Заключение

Хранилище данных строится по многоуровневой архитектуре, где каждый слой играет важную роль:

* **Staging** — буферизация и приём данных;
* **ODS** — нормализация и консолидация оперативной информации;
* **DDS** — ядро аналитики с историей изменений и бизнес-логикой;
* **Data Marts** — ориентация на конкретных потребителей данных;
* **Presentation** — доступ к данным в удобной форме.

---


