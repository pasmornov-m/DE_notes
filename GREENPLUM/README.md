# GREENPLUM

---
## Ведение

**GreenPlum** — это распределённая аналитическая СУБД (MPP — Massively Parallel Processing), построенная на основе PostgreSQL и предназначенная для хранения и обработки больших объёмов данных в задачах аналитики и Data Warehousing. Архитектура системы предполагает горизонтальное масштабирование за счёт распределения данных и вычислений между множеством сегмент-узлов, что позволяет эффективно выполнять сложные SQL-запросы над терабайтами и петабайтами информации.

---

## Структура кластера

### Серверы

Кластер Greenplum разворачивается на группе машин и обычно включает:

* один основной сервер — **master-host**;
* (опционально) один резервный мастер — **secondary master**;
* не менее двух **segment host** — серверов, на которых хранятся данные и выполняются вычисления.

При проектировании кластера следует учитывать несколько практических правил:

* Все сегментные серверы должны быть одинаковыми по аппаратным характеристикам (CPU, RAM, диски).
* Мастер-сервер обычно делают менее мощным, чем сегментные узлы, поскольку он в основном координирует запросы, а не выполняет тяжёлые вычисления.
* Предпочтительнее использовать большее количество относительно слабых машин, чем небольшое число очень мощных — это лучше соответствует MPP-архитектуре и повышает уровень параллелизма.
* Кластер можно масштабировать горизонтально — добавляя новые сегментные серверы, однако уменьшение их количества после развёртывания, как правило, не поддерживается.

Все машины соединяются между собой высокоскоростной внутренней сетью — **interconnect**, обычно со скоростью не ниже 10 Гбит/с, через которую сегменты обмениваются данными при выполнении запросов.

---

### Сегменты

#### Мастер

**Мастер-сервер** — это единая точка входа в кластер Greenplum. На нём работает экземпляр PostgreSQL, называемый **master-сегментом** (по умолчанию порт 5432).

Основные функции мастера:

* хранение системного каталога (метаданных базы данных);
* планирование и координация выполнения SQL-запросов;
* выполнение некоторых финальных операций обработки данных (например, итоговая агрегация или сортировка);
* выполнение административных операций (создание пользователей, управление объектами БД и т.д.).

При этом мастер **не хранит пользовательские данные таблиц** — они размещаются только на сегментах.

---

#### Вторичный мастер

На отдельной машине может быть развёрнут **secondary master** — зеркальная копия мастер-сегмента.

Его особенности:

* работает в режиме ожидания и не участвует в обработке запросов;
* постоянно получает резервную копию данных системного каталога;
* при отказе основного мастера администратор может вручную перевести вторичный сервер в роль нового мастера.

---

#### Праймари-сегменты

На каждом сегментном сервере размещается несколько экземпляров PostgreSQL — **primary-сегментов**. Часто используется ориентир: один сегмент примерно на каждые два ядра CPU.

Их роль:

* хранение физической части пользовательских данных;
* выполнение основной вычислительной нагрузки;
* параллельная обработка запросов.

Особенности работы:

* каждая таблица распределяет строки между всеми primary-сегментами;
* каждый сегмент содержит копию системного каталога;
* большая часть операций (фильтрация, join, агрегации) выполняется локально на сегментах;
* при необходимости сегменты обмениваются промежуточными данными через interconnect.

---

#### Зеркала праймари-сегментов

Для отказоустойчивости у каждого primary-сегмента обычно есть одно зеркало (**mirror**), расположенное на другом сервере кластера.

Особенности зеркал:

* используются для резервирования данных;
* не участвуют в обработке запросов при нормальной работе;
* автоматически активируются при отказе primary-сегмента;
* обратное переключение после восстановления выполняется вручную администратором.

---

### Политики размещения зеркал

#### Group mirroring

При **group mirroring** все зеркала сегментов одного сервера размещаются на одном другом сервере. Фактически один сервер полностью резервирует другой.

Плюсы:

* простая схема размещения;
* понятная модель отказоустойчивости.

Минусы:

* при выходе из строя одного сервера нагрузка полностью ложится на другой, что может снизить производительность кластера примерно вдвое.

---

#### Spread mirroring

При **spread mirroring** зеркала сегментов распределяются по разным серверам — по одному зеркалу на каждый из нескольких узлов.

Особенности:

* нагрузка при отказе одного сервера распределяется между несколькими узлами;
* снижение производительности происходит более плавно.

Ограничения:

* число сегментных серверов должно быть как минимум на один больше числа сегментов на сервере;
* повышается риск полного отказа при повторных сбоях, поскольку зеркала распределены по множеству машин.

---

## Работа с таблицами

### Синтаксис создания таблиц

```sql
CREATE {TEMPORARY | TEMP} | UNLOGGED] TABLE table_name (
[ { column_name data_type [ DEFAULT default_expr ]
[column_constraint [ ... ] [ ENCODING (COMPRESSTYPE={ZLIB | ZSTD | RLE_TYPE | NONE} [COMPRESSLEVEL={0-9} ]
[BLOCKSIZE={8192-2097152} ])]]
| table_constraint
| LIKE other_table [{INCLUDING|EXCLUDING} {DEFAULTS|CONSTRAINTS|INDEXES|STORAGE|COMMENTS|ALL}] ...}[, ... ] ] )
[ INHERITS ( parent_table [, ... ] ) ]
[ WITH (
[{APPENDOPTIMIZED | APPENDONLY}={TRUE|FALSE}, ]
[ BLOCKSIZE={8192-2097152}, ]
[ ORIENTATION={COLUMN|ROW}, ]
[ CHECKSUM={TRUE|FALSE},]
[ COMPRESSTYPE={ZLIB|ZSTD|RLE_TYPE|NONE}, ]
[ COMPRESSLEVEL={0-9}, ]
[ FILLFACTOR={10-100}, ]
[OIDS[=TRUE|FALSE] ]) ]
[ ON COMMIT {PRESERVE ROWS | DELETE ROWS | DROP} ]
[ TABLESPACE tablespace ]
[ DISTRIBUTED BY (column, [ ... ] ) | DISTRIBUTED RANDOMLY | DISTRIBUTED REPLICATED ]
[ PARTITION BY partition_type (column)...]
```

---

### Распределение данных таблиц

При создании таблицы в Greenplum её данные автоматически распределяются между всеми **primary-сегментами** кластера. Физически строки хранятся на сегментных серверах, причём каждая строка находится только на одном сегменте (исключение — replicated-таблицы).
Задача распределения — обеспечить **равномерную загрузку сегментов**, чтобы запросы выполнялись параллельно и без перекосов нагрузки (*data skew*).

---

#### Типы распределения

**1. `DISTRIBUTED RANDOMLY`**
Строки распределяются автоматически по алгоритму round-robin.
Подходит для таблиц без явного ключа распределения, но не оптимален для частых join-операций.

**2. `DISTRIBUTED BY (column(s))`**
Строка направляется на конкретный сегмент по хэшу указанного столбца (или набора столбцов).
Это основной и наиболее управляемый способ распределения.

**3. `DISTRIBUTED REPLICATED`**
Полная копия таблицы хранится на каждом сегменте.
Используется для небольших таблиц-справочников, чтобы ускорить join-операции.

---

#### Дополнительные особенности

* В каждой распределённой таблице (кроме replicated) есть скрытое поле `gp_segment_id`, показывающее, на каком сегменте хранится строка.
* Если тип распределения не указан, Greenplum автоматически выберет ключ (обычно первый столбец), однако на практике рекомендуется **всегда задавать распределение явно**.

---

#### Практические рекомендации по выбору ключа распределения

Главная цель — добиться равномерного распределения строк между сегментами.
Неудачный выбор ключа приводит к перекосу данных (*skew*), когда часть сегментов перегружена, а часть простаивает. Это замедляет запросы и может вызвать нехватку памяти на отдельных узлах.

Не рекомендуется использовать в качестве ключа распределения:

* столбцы с сильно неравномерным распределением значений;
* даты (часто имеют кластеризацию по времени);
* поля с большим числом `NULL`;
* столбцы, роль которых в будущих join-операциях неясна.

---

#### Влияние распределения на JOIN и план выполнения

Если таблицы распределены по ключам, используемым в join, операция может выполняться **локально на сегментах**, без дополнительного обмена данными. Это наиболее эффективный сценарий.

Если ключи распределения не совпадают, Greenplum вынужден временно перераспределять данные. В плане запроса это отражается операцией **MOTION**:

* **BROADCAST MOTION** — копирование небольшой таблицы на все сегменты.
  При больших объёмах данных нежелательно и может существенно замедлить выполнение.

* **REDISTRIBUTE MOTION** — перераспределение строк между сегментами во время запроса.
  Полностью избежать невозможно, но следует минимизировать. Может увеличить нагрузку на сеть и вызвать перекос сегментов.

---

#### Рекомендации по эффективному использованию кластера

* Используйте одинаковые типы данных в столбцах, участвующих в join.
* Старайтесь выбирать ключи распределения, совпадающие с ключами соединения таблиц.
* Контролируйте равномерность данных, чтобы избежать skew.
* Применяйте `DISTRIBUTED REPLICATED` для небольших справочников — это позволяет выполнять join без операций MOTION.

---

### Партицирование

**Партиционирование** — это способ ускорить выполнение запросов за счёт разделения одной большой таблицы на логические части — **партиции**. Каждая партиция хранит только часть данных, а при выполнении запроса система может читать не всю таблицу, а только нужные разделы. Это особенно эффективно, если в запросах часто используются фильтры в `WHERE`.

---

#### Общие сведения

* **Partition elimination** — механизм, который позволяет Greenplum сканировать только те партиции, которые соответствуют условиям запроса. Это основная причина ускорения работы.
* **Ключ партиционирования** — столбец, по которому определяется, в какую партицию попадёт строка.
  При многоуровневом партиционировании используется отдельный ключ на каждом уровне.
* Поддерживаются два типа партиционирования:

  * `RANGE` — разделение по диапазонам значений (например, по датам);
  * `LIST` — разделение по списку значений (например, по регионам).
* Для `RANGE` можно:

  * явно задавать границы партиций;
  * создавать партиции автоматически по заданному интервалу.
* Партиционирование может быть **многоуровневым** (например, сначала по году, затем по месяцу).
* Партиционированная таблица — это фактически набор связанных таблиц. Внутри используются механизмы наследования (`INHERITS`) и ограничения (`CHECK`). Такая структура задаётся при создании таблицы.

---

#### Практические особенности и ограничения

* На одном уровне допускается примерно до **32 тысяч партиций**, но на практике рекомендуется не превышать **~1000 партиций** на таблицу — большое количество ухудшает планирование запросов и администрирование.
* Для ограничений `PRIMARY KEY` и `UNIQUE` необходимо включать в состав ключа столбец партиционирования.
* Можно создать `DEFAULT PARTITION` — раздел для строк, которые не попали ни в одну из заданных партиций.
  Такая партиция сканируется всегда и не является обязательной.
* Таблицы с распределением `DISTRIBUTED REPLICATED` нельзя партиционировать.
* Массовая загрузка данных напрямую в партиционированную таблицу может быть менее эффективной. Часто применяют подход:

  1. загрузка данных во временную обычную таблицу;
  2. замена партиции через `EXCHANGE PARTITION`.
* Механизм partition elimination работает с операторами:
  `=`, `<`, `<=`, `>`, `>=`, `<>`.
* Он поддерживает функции типов `STABLE` и `IMMUTABLE`, но не работает с `VOLATILE`.
* Поля, по которым выполнено партиционирование, можно обновлять (`UPDATE`), однако такие операции могут быть затратными.
* На каждом уровне партиционирования допускается только **один ключ** — составные ключи на одном уровне не поддерживаются.

Пример

```sql
CREATE TABLE server_logs (
    log_id bigint,
    log_timestamp timestamp,
    message text,
    severity_level text -- 'ERROR', 'WARNING', 'INFO'
)
-- Распределение данных по узлам кластера (Greenplum)
DISTRIBUTED BY (log_id) 

-- Основная партиция: по времени
PARTITION BY RANGE (log_timestamp) 

-- Подпартиция: по уровню важности лога
SUBPARTITION BY LIST (severity_level) 
SUBPARTITION TEMPLATE (
    SUBPARTITION crit VALUES ('ERROR', 'CRITICAL'), -- Группируем ошибки вместе
    SUBPARTITION warn VALUES ('WARNING'),
    SUBPARTITION info VALUES ('INFO', 'DEBUG'),
    DEFAULT SUBPARTITION other_levels -- Для неизвестных типов
)

-- Определение временных интервалов (Партиции будут созданы автоматически по шаблону)
(
    START (date '2023-01-01') INCLUSIVE 
    END (date '2023-04-01') EXCLUSIVE 
    EVERY (INTERVAL '1 week'), -- Разбиваем по 1 неделе, а не по месяцу
    DEFAULT PARTITION archive_logs -- Для дат вне диапазона
);
```

Партицию можно разделить на две, используя как разделитель выражение после `AT`

```sql
-- Разделяем партицию, которая содержит дату '2023-01-02' (это 1-я неделя)
ALTER TABLE server_logs SPLIT PARTITION FOR ('2023-01-02')
AT ('2023-01-04 00:00:00')
INTO (PARTITION logs_jan_start, PARTITION logs_jan_crash_period);
```

Также можно отделить новую партицию от дефолтной

```sql
ALTER TABLE server_logs SPLIT DEFAULT PARTITION
START ('2023-04-01') INCLUSIVE
END ('2023-04-08') EXCLUSIVE
INTO (PARTITION logs_april_week1, DEFAULT PARTITION);
```

Добавить партицию можно только в пустое место, пересечения не допускаются. Также не получится добавить новую партицию, если есть `default` партиция.

#### Замена партиций

Возможно заменить партицию на таблицу с такой же структурой. Также, это даёт возможность создавать полиморфные объекты за счёт замены на таблицы с иными настройками хранениями. Можно менять партиции на внешние таблицы (только в режиме чтения). При замене происходит обмен ссылками на таблицы, они переименовываются.

Пример

```sql
CREATE TABLE logs_april_week1_new (LIKE server_logs);
ALTER TABLE server_logs EXCHANGE PARTITION logs_april_week1 WITH TABLE logs_april_week1_new WITH VALIDATION;
```

Опции операции:
* WITH VALIDATION – проверит, что все записи в таблице соответствуют отрезку ключа партиционирования. При несовпадении операция завершится с ошибкой.
* WITHOUT VALIDATION – ничего не проверяется. Используется при замене партиции на внешнюю таблицу.

---

## Типы данных

При проектировании таблиц в Greenplum рекомендуется выбирать **наименьшие достаточные типы данных**, чтобы снизить расход памяти, ускорить обработку и уменьшить объём передаваемых данных между сегментами.
Например: использовать `INT` вместо `BIGINT`, если диапазон значений позволяет, или `VARCHAR`/`TEXT` вместо `CHAR(n)` при переменной длине строк.

Дополнительные рекомендации:

* Используйте **специализированные типы данных**, когда они отражают семантику данных (`INET`, `CIDR`, `UUID`, `JSONB`, `MACADDR` и др.).
* В столбцах, участвующих в `JOIN`, всегда применяйте **одинаковые типы данных**, чтобы избежать лишних преобразований и ухудшения планов выполнения.
* Избегайте универсальных типов (`TEXT`, `NUMERIC`) без необходимости — они часто тяжелее в обработке.

---

### Основные категории типов данных в Greenplum

Greenplum наследует большинство типов PostgreSQL.

#### Числовые типы

* `SMALLINT` — 2 байта, небольшие целые числа.
* `INTEGER` / `INT` — стандартный целочисленный тип.
* `BIGINT` — большие целые значения.
* `NUMERIC(p,s)` / `DECIMAL` — точные числа с фиксированной точностью (медленнее, но без потерь точности).
* `REAL`, `DOUBLE PRECISION` — числа с плавающей точкой.
* `MONEY` — денежные значения (используется редко, чаще применяют `NUMERIC`).

Используйте целочисленные типы там, где это возможно — они быстрее и компактнее.

---

#### Строковые типы

* `TEXT` — строка произвольной длины (часто оптимальный выбор).
* `VARCHAR(n)` — строка с ограничением длины.
* `CHAR(n)` — фиксированная длина (может приводить к лишним затратам памяти).

Практика показывает, что `TEXT` и `VARCHAR` почти всегда предпочтительнее `CHAR`.

---

#### Дата и время

* `DATE` — только дата.
* `TIME` — только время.
* `TIMESTAMP` — дата и время без часового пояса.
* `TIMESTAMPTZ` — дата и время с учётом часового пояса.
* `INTERVAL` — временные интервалы.

Для аналитических систем чаще всего используется `TIMESTAMP` или `TIMESTAMPTZ`.

---

#### Сетевые и системные типы

* `INET`, `CIDR` — IP-адреса и сети.
* `MACADDR` — MAC-адреса.
* `UUID` — уникальные идентификаторы.
* `BOOLEAN` — логические значения.

Эти типы позволяют хранить данные компактнее и обеспечивают корректные операции сравнения.

---

#### Бинарные и прочие типы

* `BYTEA` — бинарные данные.
* `ARRAY` — массивы значений.
* `XML` — XML-документы.
* `ENUM` — ограниченные наборы значений.
* пользовательские типы (UDT).

---

### JSON

В Greenplum поддерживаются два типа для хранения JSON-документов: `json` и `jsonb`.

#### `json`

* Хранится как текст с сохранением исходного форматирования и пробелов.
* Допускает дублирующиеся ключи; актуальным считается последнее значение.
* Быстрее при простой записи данных, но хуже подходит для поиска и индексации.

#### `jsonb`

* Хранится в бинарном формате.
* Пробелы и форматирование не сохраняются.
* При наличии дублирующих ключей сохраняется только последнее значение.
* Поддерживает индексы (`GIN`, `B-TREE`) и эффективные операции поиска.
* Обычно является предпочтительным вариантом для аналитических задач.

---

## Запросы


### Выполнение запроса

Процесс выполнения SQL-запроса в Greenplum распределён между мастер-сервером и сегментами и состоит из нескольких этапов:

1. **Отправка запроса**
   Клиент подключается к мастер-серверу (обычно порт 5432) и отправляет SQL-запрос. Мастер является единой точкой входа в кластер.

2. **Разбор запроса (Parsing)**
   PostgreSQL listener принимает подключение, после чего:

   * проверяется синтаксис и семантика запроса;
   * строится внутреннее дерево запроса (*query tree*).

3. **Оптимизация запроса**
   Разобранный запрос передаётся оптимизатору на мастере.
   В Greenplum используются два оптимизатора:

   * **GPORCA** — основной cost-based оптимизатор, разработанный специально для MPP-архитектуры Greenplum. Обычно строит более эффективные планы для сложных аналитических запросов.
   * **PostgreSQL Optimizer** — используется как fallback для сценариев, которые GPORCA не поддерживает.

   Оптимизатор:

   * оценивает стоимость различных вариантов выполнения;
   * учитывает статистику таблиц и распределение данных;
   * строит оптимальный план выполнения.

4. **Диспетчеризация и выполнение**
   Мастер формирует план и передаёт задачи сегментам.
   Основные вычисления выполняются **параллельно на primary-сегментах**, включая:

   * сканирование таблиц;
   * фильтрацию;
   * join-операции;
   * частичные агрегации.

5. **Сбор результатов**
   Сегменты возвращают промежуточные результаты мастеру, который может выполнить финальные операции:

   * глобальную агрегацию;
   * окончательную сортировку;
   * формирование итогового результата.

Важно помнить: SQL — декларативный язык, поэтому пользователь описывает желаемый результат, а не способ его получения. Все решения о стратегии выполнения принимает оптимизатор.

---

### Спилл-файлы (Spill files)

Если сегменту не хватает оперативной памяти для промежуточных операций (например, hash join или сортировки), часть данных временно записывается на диск — создаются **spill-файлы**.

Это происходит при:

* перераспределении данных (`REDISTRIBUTE MOTION`);
* больших hash-таблицах;
* крупных сортировках и агрегациях.

Особенности:

* замедляют выполнение запросов из-за операций ввода-вывода;
* могут указывать на недостаток памяти или неэффективный план;
* директории хранения spill-файлов можно конфигурировать отдельно от основных данных.

---

### План запроса

**План запроса** — это дерево операций, которые необходимо выполнить для получения результата.
Каждый узел дерева представляет отдельную операцию (scan, join, motion, aggregate и т.д.).

#### Просмотр плана

Для анализа используются команды:

```sql
EXPLAIN SELECT * FROM table2 WHERE id < 101;
```

* `EXPLAIN` — показывает план выполнения без запуска запроса.
* `EXPLAIN ANALYZE` — выполняет запрос и выводит фактическую статистику выполнения.

#### Стоимость плана

Каждый шаг имеет параметр `cost` — условную оценку затрат.
Она не равна времени выполнения напрямую, но используется оптимизатором для выбора лучшего варианта.

---

### Что анализировать в плане запроса

При разборе плана важно обращать внимание на:

* Какие операции имеют наибольшую стоимость?
* Насколько точно оптимизатор оценивает количество строк (estimated vs actual)?
* Собрана ли статистика (`ANALYZE`)?
* Есть ли перекос распределения данных?
* Работает ли **partition elimination** (не сканируются ли все партиции)?
* При hash join — строится ли hash-таблица по меньшей таблице?
* Присутствуют ли операции `MOTION`:

  * `BROADCAST MOTION` — рассылка таблицы по всем сегментам;
  * `REDISTRIBUTE MOTION` — перераспределение данных между сегментами.
* Используется ли `NESTED LOOP` там, где можно применить `HASH JOIN`?
* Создаются ли spill-файлы (признак нехватки памяти или плохого плана)?

---

## Индексы

**Индекс** — это вспомогательная структура данных, которая ускоряет поиск строк по условиям (`WHERE`, `JOIN`, `ORDER BY`).
По сути, индекс хранит отсортированную информацию о значениях столбцов и ссылки на строки основной таблицы, позволяя СУБД находить нужные данные без полного сканирования таблицы (*full scan*).

Однако важно учитывать специфику Greenplum: это аналитическая MPP-система, где производительность чаще достигается за счёт **распределения данных, партиционирования и оптимальных планов**, а не за счёт индексов. Поэтому индексы обычно применяются после оптимизации структуры данных и запросов.

---

### Основные виды индексов

#### BTREE

* Тип индекса по умолчанию.
* Подходит для условий:

  * `=`, `<`, `<=`, `>`, `>=`;
  * сортировок (`ORDER BY`);
  * диапазонных запросов.
* Эффективен для выборки небольшого числа строк.
* Чаще используется в OLTP-сценариях, но может применяться и в DWH для точечных запросов.

---

#### BITMAP

* Используется для столбцов с **низкой или средней кардинальностью** (например, статусы, категории).
* Эффективен при аналитических запросах с большим количеством чтений и редкими обновлениями.
* Хорошо работает при фильтрации по нескольким условиям одновременно.
* Не подходит для таблиц с частыми `UPDATE`/`DELETE`.

---

#### GIN (Generalized Inverted Index)

* Обратный индекс, предназначенный для составных значений.
* Используется с типами:

  * `JSONB`;
  * массивы (`ARRAY`);
  * полнотекстовый поиск (`tsvector`).
* Позволяет быстро находить строки по элементам внутри структуры.

---

#### GIST (Generalized Search Tree)

* Универсальный индекс для специализированных типов данных.
* Применяется, например, для:

  * геометрических данных;
  * диапазонов;
  * некоторых расширений.
* Используется реже и обычно в специфических сценариях.

---

### Особенности использования индексов в Greenplum (DWH)

* В аналитических системах индексы — **не основной инструмент ускорения**.
  Сначала оптимизируют:

  * распределение данных (`DISTRIBUTED BY`);
  * партиционирование;
  * структуру запросов.
* Индексы эффективны, когда:

  * выбирается небольшое количество строк;
  * используются точечные фильтры;
  * выполняются частые lookup-запросы.

---

### Практические рекомендации

* Не создавайте индексы «на всякий случай» — они:

  * увеличивают размер таблиц;
  * замедляют вставку и обновление данных;
  * требуют обслуживания.

* При массовой загрузке данных:

  1. удалите индексы;
  2. загрузите данные;
  3. создайте индексы заново — это быстрее, чем поддерживать их во время загрузки.

* Избегайте индексации столбцов:

  * с очень низкой селективностью (например, `BOOLEAN`);
  * которые часто обновляются;
  * участвующих в больших аналитических сканированиях (индекс всё равно не будет использоваться).

---

## Транзакции

Транзакция — это группа операций чтения и записи, которые выполняются как единое целое: либо все изменения фиксируются (`COMMIT`), либо все откатываются (`ROLLBACK`).
Транзакции обеспечивают целостность данных и корректную работу при параллельных запросах.

**Пример транзакции:**

```sql
BEGIN;
UPDATE accounts SET balance = balance - 100.00 WHERE name = 'Peter';
UPDATE accounts SET balance = balance + 100.00 WHERE name = 'Ivan';
COMMIT;
```

---

### Свойства ACID

Транзакции в Greenplum (как и в PostgreSQL) соответствуют принципам ACID:

* **Atomicity (Атомарность)** — все операции внутри транзакции выполняются полностью или не выполняются вовсе.
* **Consistency (Согласованность)** — транзакция переводит базу данных из одного корректного состояния в другое, соблюдая ограничения и правила.
* **Isolation (Изоляция)** — параллельные транзакции не мешают друг другу; результат их выполнения эквивалентен последовательному выполнению.
* **Durability (Надёжность)** — после `COMMIT` изменения сохраняются даже при сбоях системы.

---

### Уровни изоляции

Уровень изоляции определяет, какие изменения других транзакций видны текущей транзакции.
Задаётся после начала транзакции:

```sql
BEGIN;
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;
```

Доступные уровни:

* **READ UNCOMMITTED** — не поддерживается в Greenplum (фактически соответствует READ COMMITTED).

* **READ COMMITTED** — транзакция видит:

  * свои изменения;
  * только зафиксированные изменения других транзакций.
    Используется по умолчанию.

* **REPEATABLE READ** — все запросы внутри транзакции видят согласованный снимок данных на момент первого запроса.
В Greenplum фантомные чтения на этом уровне не допускаются.

* **SERIALIZABLE** — формально доступен, но по поведению соответствует REPEATABLE READ.
  Возможны ошибки сериализации — приложение должно уметь повторять транзакцию.

---

### MVCC (Multi-Version Concurrency Control)

Greenplum использует механизм MVCC — многоверсионность строк для обеспечения параллельной работы без блокировок на чтение.

Основные принципы:

* Каждая транзакция получает уникальный идентификатор.
* Для каждой строки хранятся технические поля:

  * `xmin` — транзакция, которая добавила строку;
  * `xmax` — транзакция, которая её удалила.
* `UPDATE` реализуется как:

  * вставка новой версии строки;
  * пометка старой версии как удалённой.
* Строки физически не удаляются сразу — они остаются в таблице до очистки.
* При чтении каждая транзакция видит только те версии строк, которые допустимы её уровнем изоляции.
* В heap-таблицах служебные поля хранятся в самой строке, в AO-таблицах — во внутренних служебных структурах.

---

### VACUUM и очистка данных

Из-за MVCC в таблицах со временем накапливаются «мёртвые» строки. Для их очистки используется `VACUUM`.

* **VACUUM**:

  * удаляет устаревшие версии строк;
  * освобождает место внутри таблицы;
  * не блокирует таблицу полностью.

* **VACUUM FULL**:

  * полностью перестраивает таблицу;
  * уменьшает её физический размер;
  * требует эксклюзивной блокировки и используется редко.

Практические рекомендации:

* При регулярном запуске `VACUUM` необходимость в `VACUUM FULL` возникает редко.
* Системные каталоги также требуют периодической очистки — особенно при большом количестве DDL-операций.
* Большое количество «мёртвых» строк приводит к **bloat** — разрастанию таблиц и ухудшению производительности.

---

## Внешние таблицы

Внешняя таблица (ВТ), EXTERNAL TABLE - метаобъект, предназначенные для доступа к данным, хранящимся вне СУБД.

* ВТ не хранят данные, они запрашиваются или отправляются при каждом запросе заново.

* ВТ не могут использоваться в запросах как обычные таблицы.

* ВТ бывают: READABLE и WRITABLE - писать и читать в рамках одного объекта нельзя. Также бывают WEB - только для протокола HTTP и запуска системных команд в окружении ОС кластера. Обычные таблицы предназначены для подключения к файлам или другим системам.

* ВТ на чтение всегда вызывают REDISTRIBUTE MOTION при запросе данных, на запись - не всегда.

### Протоколы

Протокол - метод доступа к источникам данных. Для WEB внешних таблиц:

* http:// - доступ к данным на HTTP-сервере. Только чтение. HTTPS не поддерживается.

* EXECUTE - Выполнение команды в операционной системе кластера.

Для простых внешних таблиц:

* file:// - доступ к файлам на ФС сегментов. С мастера данные получить нельзя. Для простых внешних таблиц.

* gpfdist:// - доступ к GPFDIST-серверу. Для простых внешних таблиц.

* gpfdists:// - доступ к SSL-версии GPFDIST. Для простых внешних таблиц.

* s3:// - доступ к файлам на Amazon S3 bucket.

* pxf:// - доступ к внешним ресурсам через Platform eXtension Framework.

* Custom – можно создавать свои протоколы с помощью C-библиотек.

Формат - метод работы с потоком данных:

* CSV

* TEXT - отличается от CSV дефолтными настройками и позволяет установить DELIMETER=OFF для загрузки строк целиком.

* CUSTOM - можно создавать свои форматы с помощью функций, например, часто применяется с протоколом PXF.

```sql
CREATE [READABLE] EXTERNAL TABLE table_name
( column_name data_type [, ...] | LIKE other_table )
LOCATION (protocol://location[options]' [, ...])
[ON MASTER] -- только для S3 и custom
FORMAT 'TEXT'
[( [HEADER] -- игнорировать первую строку. Недоступно для PXF
[DELIMITER [AS] 'delimiter' | 'OFF']
[NULL [AS] 'null string']
[ESCAPE [AS] 'escape' | 'OFF']
[NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF']
[FILL MISSING FIELDS] )] -- если не хватает столбцов, заполнять NULL
```

Внешняя таблица, читающая по протоколу file все csv-файлы из директорий /data/expense/ на трех разных сегментных серверах.

```sql
CREATE READABLE EXTERNAL TABLE ext_expenses (
name text, date date, amount float4, category text, desc1 text )
LOCATION ('file://sdw1/data/expense/*.csv',
'file://sdw2/data/expense/*.csv',
'file://sdw3/data/expense/*.csv')
FORMAT 'CSV' (HEADER);
```

Внешняя таблица, читающая по протоколу file файл hosts на первом сегментном сервере:

```sql
CREATE READABLE EXTERNAL TABLE ext_expenses (name text)
LOCATION ('file://sdw1/etc/hosts') FORMAT 'TEXT' (DELIMITER 'OFF');
```

### PXF

Platform Extension Framework (PXF) – это отдельное ПО, выступающее посредником между сегментами кластера и сторонними системами (базами данных, хранилищами).

Реализован как отдельный JAVA-сервис, работающий на всех сегмент-серверах под своими пользователями. Запускается одна копия PXF на каждом сегментном сервере. Сегменты обращаются к своей копии через REST. Содержит подключаемые модуля - коннекторы и плагины, необходимые для доступа к внешним системам. Возможность чтения и записи зависит от плагина, может быть одно и двунаправленным. 

По умолчанию работа с внешней системой идёт от имени самого PXF. User Impersonation позволяет делать это от имени пользователя, выполняющего запрос. Работает для соединений с Hadoop и по JDBC.

По умолчанию во время запроса в фильтрацией (where) с источника извлекаются все строки, а фильтрация производится уже в БД. **Pushdown** позволяет передать фильтр из запроса на внешний источник, чтобы отфильтровать строки там, экономя ресурсы.

При работе с PXF многие параметры задаются непосредственно в строке **LOCATION**. Строка формируется следующим образом:

* Протокол - pxf

* Локация ресурса для чтения или записи (директория, файл, таблица)

* Набор опций, часть из которых - общие, а часть зависит от коннектора

```sql
LOCATION ('pxf://<path-to-hdfs-file>?[<option>=<value>][&<option>=<value>][…]')
```

Общие опции

* SERVER - профиль конфигурации подключения

* PROFILE - указатель на коннектор

```sql
LOCATION ('pxf://data/my_file.txt?PROFILE=hdfs:text&SERVER=devHadoop1')
```

---

## COPY

Команда COPY - самый низкоуровневый способ импортировать и экспортировать данные. Работает как на мастере, так и на сегментах. Интегрируется со сторонним ПО. Работает с текстом и с бинарными данными.

Пример

```sql
COPY table [(column [, ...])] FROM {'file' | PROGRAM 'command' | STDIN}
[ [WITH]
[ON SEGMENT] -- локально или на мастере.
[BINARY] -- текстово или бинарно.
[OIDS] -- копировать OID – только для таблиц, содержащих OID каждой строки.
[HEADER] -- игнорировать первую строку.
[DELIMITER [ AS ] 'delimiter'] – разделитель.
[NULL [ AS ] 'null string'] – NULL.
[ESCAPE [ AS ] 'escape' | 'OFF'] -- escape-символ.
[NEWLINE [ AS ] 'LF' | 'CR' | 'CRLF'] -- символ перевода строки.
[CSV [QUOTE [ AS ] 'quote'] -- кавычки, дефолт – двойные кавычки.
[FORCE NOT NULL column [, ...]] -- пусто вместо NULL.
[FILL MISSING FIELDS] -- если не хватает столбцов, заполнять NULL.
[[LOG ERRORS] -- логировать записи, на которых возникла ошибка (только со след. опцией).
SEGMENT REJECT LIMIT count [ROWS | PERCENT] ] -- допустимое количество записей с ошибками.
```

```sql
COPY {table [(column [, ...])] | (query)} TO {'file' | PROGRAM 'command' | STDOUT}
[ [WITH]
[ON SEGMENT]
[BINARY]
[OIDS]
[HEADER]
[DELIMITER [ AS ] 'delimiter']
[NULL [ AS ] 'null string']
[ESCAPE [ AS ] 'escape' | 'OFF']
[CSV [QUOTE [ AS ] 'quote']
[FORCE QUOTE column [, ...]] ] -- брать в кавычки всё
[IGNORE EXTERNAL PARTITIONS ] -- если в экспортируемой таблице есть внешние партиции, упасть с ошибкой или игнорировать их.
```

Нюансы

* Для запросов, представлений и внешних объектов: `COPY (SELECT * FROM my_table) TO ...`

* На папки, файлы и программы должны быть даны соответствующие права пользователю gpadmin

* COPY умеет валидировать xml для типа xml

* Не суперпользователи могут читать/писать только в клиентский stdin/stdout

---

## Пользовательские функции

Функция - объект, в котором содержится исполняемый алгоритм, описанный на одном из доступных языков. Функцию можно выполнить с помощью SQL запроса. Процедур и пользовательских триггеров в GP нет. Функции принимают параметры на вход, возвращают результат в виде одной или нескольких строк. Также в них можно выполнять запросы.

Каждая функция принадлежит одному из классов:

* IMMUTABLE - значение функции зависит только от её аргументов

* STABLE - значение функции может меняться от транзакции к транзакции, но не может меняться в рамках одной транзакции

* VOLATILE (default) - значение функции может меняться в ходе выполнения. Часто такой тип функции выполняется только на мастере.

Если вы уверены, что функция относится к классу IMMUTABLE или STABLE - стоит это указать.

**Место выполнения**

Функции можно выполнять с помощью двух типов команд:

* SELECT function() - как правило выполняется на мастере, если не используется параметр EXECUTE ON ALL SEGMENTS

* SELECT function(field) FROM table - чаще всего будет выполняться на сегментах, если не используется параметр EXECUTE ON MASTER

Также есть параметр EXECUTE ON ANY, при котором функция может исполняться как на мастере, так и на сегментах, GP сам решает где это произойдёт.

Пример создания функции

```sql
CREATE [OR REPLACE] FUNCTION name ( [ [argmode] [argname] argtype [ { DEFAULT | = } default_expr ] [, ...] ] )
[ RETURNS rettype | RETURNS TABLE ( column_name column_type [, ...] ) ]
{ LANGUAGE langname
| WINDOW
| IMMUTABLE
| STABLE
| VOLATILE
| CALLED ON NULL INPUT | RETURNS NULL ON NULL INPUT | STRICT
| NO SQL | CONTAINS SQL | READS SQL DATA | MODIFIES SQL
| EXECUTE ON { ANY | MASTER | ALL SEGMENTS | INITPLAN }
| COST execution_cost | SET configuration_parameter { TO value | = value | FROM CURRENT }
| AS 'definition' | AS 'obj_file', 'link_symbol' } ... 
```

Пример функции

```sql
CREATE FUNCTION add(integer, integer) RETURNS integer
AS 'select $1 + $2;'
LANGUAGE SQL
IMMUTABLE
RETURNS NULL ON NULL INPUT;
--
CREATE OR REPLACE FUNCTION t1_calc( name text) RETURNS
integer
AS $$
DECLARE
t1_row table1%ROWTYPE;
calc_int table1.f3%TYPE;
BEGIN
SELECT * INTO t1_row FROM table1 WHERE table1.f1 = $1 ;
calc_int = (t1_row.f2 * t1_row.f3)::integer ;
RETURN calc_int ;
END;
$$ LANGUAGE plpgsql VOLATILE;
```

### Анонимные блоки

Анонимные блоки – выполняемый код, не сохраненный в виде объекта.

```sql
DO $$
DECLARE
t1_row table1%ROWTYPE;
calc_int table1.f3%TYPE;
BEGIN
SELECT * INTO t1_row FROM table1, list WHERE table1.f1 = list.column1 ;
calc_int = (t1_row.f2 * t1_row.f3)::integer ;
RAISE NOTICE 'calculated value is %', calc_int ;
END $$ LANGUAGE plpgsql ;
```